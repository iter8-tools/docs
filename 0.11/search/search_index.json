{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Iter8 \u00b6","title":"Home"},{"location":"#iter8","text":"","title":"Iter8"},{"location":"contributing/","text":"Overview \u00b6 Welcome! We are delighted that you want to contribute to Iter8! \ud83d\udc96 As you get started, you are in the best position to give us feedback on key areas including: Problems found during setup of Iter8 Gaps in our getting started tutorial and other documentation Bugs in our test and automation scripts If anything doesn't make sense, or doesn't work when you run it, please open a bug report and let us know! Ways to contribute \u00b6 We welcome many types of contributions including: CLI and Iter8 experiment chart Docs CI, builds, and tests Reviewing pull requests Ask for help \u00b6 The best ways to reach us with a question is to ask... On the original GitHub issue In the #development channel in the Iter8 Slack workspace During our community meetings Find an issue \u00b6 Iter8 issues are tracked here . Pull request lifecycle \u00b6 Your PR is associated with one (and infrequently, with more than one) GitHub issue . You can start the submission of your PR as soon as this issue has been created. Follow the standard GitHub fork and pull request process when creating and submitting your PR. The associated GitHub issue might need to go through design discussions and may not be ready for development. Your PR might require new tests; these new or existing tests may not yet be running successfully. At this stage, keep your PR as a draft , to signal that it is not yet ready for review. Once design discussions are complete and tests pass, convert the draft PR into a regular PR to signal that it is ready for review. Additionally, post a message in the #development Slack channel of the Iter8 Slack workspace with a link to your PR. This will expedite the review. You can expect an initial review within 1-2 days of submitting a PR, and follow up reviews (if any) to happen over 2-5 days. Use the #development Slack channel of Iter8 Slack workspace to ping/bump when the pull request is ready for further review or if it appears stalled. Iter8 releases happen frequently. Once your PR is merged, you can expect your contribution to show up live in a short amount of time at https://iter8.tools . Sign Your Commits \u00b6 Licensing is important to open source projects. It provides some assurances that the software will continue to be available based under the terms that the author(s) desired. We require that contributors sign off on commits submitted to our project's repositories. The Developer Certificate of Origin (DCO) is a way to certify that you wrote and have the right to contribute the code you are submitting to the project. Read GitHub's documentation on signing your commits . You sign-off by adding the following to your commit messages. Your sign-off must match the Git user and email associated with the commit. This is my commit message Signed-off-by: Your Name <your.name@example.com> Git has a -s command line option to do this automatically: git commit -s -m 'This is my commit message' If you forgot to do this and have not yet pushed your changes to the remote repository, you can amend your commit with the sign-off by running: git commit --amend -s Development environment setup \u00b6 The Iter8 project consists of the following repos. iter8-tools/iter8 : source for the Iter8 CLI and experiment charts iter8-tools/docs : source for Iter8 docs iter8-tools/homebrew-iter8 : Homebrew formula for the Iter8 CLI iter8-tools/iter8 \u00b6 This is the source repo for Iter8 CLI. Clone iter8 \u00b6 git clone https://github.com/iter8-tools/iter8.git Build Iter8 \u00b6 make build Install Iter8 locally \u00b6 make clean install iter8 version Run unit tests and see coverage information \u00b6 make tests make coverage make htmlcov iter8-tools/docs \u00b6 This is the source repo for Iter8 documentation. Clone docs \u00b6 git clone https://github.com/iter8-tools/docs.git Locally serve docs \u00b6 From the root of this repo: python3 -m venv .venv source .venv/bin/activate pip install -r requirements.txt mkdocs serve -s You can now see your local docs at http://localhost:8000 . You will also see live updates to http://localhost:8000 as you update the contents of the docs folder.","title":"Contributing"},{"location":"contributing/#overview","text":"Welcome! We are delighted that you want to contribute to Iter8! \ud83d\udc96 As you get started, you are in the best position to give us feedback on key areas including: Problems found during setup of Iter8 Gaps in our getting started tutorial and other documentation Bugs in our test and automation scripts If anything doesn't make sense, or doesn't work when you run it, please open a bug report and let us know!","title":"Overview"},{"location":"contributing/#ways-to-contribute","text":"We welcome many types of contributions including: CLI and Iter8 experiment chart Docs CI, builds, and tests Reviewing pull requests","title":"Ways to contribute"},{"location":"contributing/#ask-for-help","text":"The best ways to reach us with a question is to ask... On the original GitHub issue In the #development channel in the Iter8 Slack workspace During our community meetings","title":"Ask for help"},{"location":"contributing/#find-an-issue","text":"Iter8 issues are tracked here .","title":"Find an issue"},{"location":"contributing/#pull-request-lifecycle","text":"Your PR is associated with one (and infrequently, with more than one) GitHub issue . You can start the submission of your PR as soon as this issue has been created. Follow the standard GitHub fork and pull request process when creating and submitting your PR. The associated GitHub issue might need to go through design discussions and may not be ready for development. Your PR might require new tests; these new or existing tests may not yet be running successfully. At this stage, keep your PR as a draft , to signal that it is not yet ready for review. Once design discussions are complete and tests pass, convert the draft PR into a regular PR to signal that it is ready for review. Additionally, post a message in the #development Slack channel of the Iter8 Slack workspace with a link to your PR. This will expedite the review. You can expect an initial review within 1-2 days of submitting a PR, and follow up reviews (if any) to happen over 2-5 days. Use the #development Slack channel of Iter8 Slack workspace to ping/bump when the pull request is ready for further review or if it appears stalled. Iter8 releases happen frequently. Once your PR is merged, you can expect your contribution to show up live in a short amount of time at https://iter8.tools .","title":"Pull request lifecycle"},{"location":"contributing/#sign-your-commits","text":"Licensing is important to open source projects. It provides some assurances that the software will continue to be available based under the terms that the author(s) desired. We require that contributors sign off on commits submitted to our project's repositories. The Developer Certificate of Origin (DCO) is a way to certify that you wrote and have the right to contribute the code you are submitting to the project. Read GitHub's documentation on signing your commits . You sign-off by adding the following to your commit messages. Your sign-off must match the Git user and email associated with the commit. This is my commit message Signed-off-by: Your Name <your.name@example.com> Git has a -s command line option to do this automatically: git commit -s -m 'This is my commit message' If you forgot to do this and have not yet pushed your changes to the remote repository, you can amend your commit with the sign-off by running: git commit --amend -s","title":"Sign Your Commits"},{"location":"contributing/#development-environment-setup","text":"The Iter8 project consists of the following repos. iter8-tools/iter8 : source for the Iter8 CLI and experiment charts iter8-tools/docs : source for Iter8 docs iter8-tools/homebrew-iter8 : Homebrew formula for the Iter8 CLI","title":"Development environment setup"},{"location":"contributing/#iter8-toolsiter8","text":"This is the source repo for Iter8 CLI.","title":"iter8-tools/iter8"},{"location":"contributing/#clone-iter8","text":"git clone https://github.com/iter8-tools/iter8.git","title":"Clone iter8"},{"location":"contributing/#build-iter8","text":"make build","title":"Build Iter8"},{"location":"contributing/#install-iter8-locally","text":"make clean install iter8 version","title":"Install Iter8 locally"},{"location":"contributing/#run-unit-tests-and-see-coverage-information","text":"make tests make coverage make htmlcov","title":"Run unit tests and see coverage information"},{"location":"contributing/#iter8-toolsdocs","text":"This is the source repo for Iter8 documentation.","title":"iter8-tools/docs"},{"location":"contributing/#clone-docs","text":"git clone https://github.com/iter8-tools/docs.git","title":"Clone docs"},{"location":"contributing/#locally-serve-docs","text":"From the root of this repo: python3 -m venv .venv source .venv/bin/activate pip install -r requirements.txt mkdocs serve -s You can now see your local docs at http://localhost:8000 . You will also see live updates to http://localhost:8000 as you update the contents of the docs folder.","title":"Locally serve docs"},{"location":"roadmap/","text":"Roadmap \u00b6 Comparing multiple versions based on business rewards Notifications AutoX service for automatically launching and managing Iter8 experiments A/B(/n) testing SDK DevSecOps experiments MLOps concept drift detection experiments Iter8 Tekton task Spike/ramp testing","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"Comparing multiple versions based on business rewards Notifications AutoX service for automatically launching and managing Iter8 experiments A/B(/n) testing SDK DevSecOps experiments MLOps concept drift detection experiments Iter8 Tekton task Spike/ramp testing","title":"Roadmap"},{"location":"community/community/","text":"Community \u00b6 Meetings \u00b6 Everyone is welcome to join our community meetings. They are on the 3 rd Wednesday of each month from 11:00 AM \u2013 12:00 PM EST/EDT. Here is the meeting link . View the calendar or subscribe ( Google Calendar , iCalendar file ). Feel free to bring discussion topics to the meeting. If you would like to present a demo, please drop us a note in the Iter8 Slack workspace . Our meetings are also recorded and publicly available on our YouTube channel . Slack \u00b6 Iter8 Slack workspace is here . Join the Iter8 Slack for usage and development related discussions. GitHub Issues \u00b6 GitHub issues for all Iter8 repos are managed here .","title":"Community"},{"location":"community/community/#community","text":"","title":"Community"},{"location":"community/community/#meetings","text":"Everyone is welcome to join our community meetings. They are on the 3 rd Wednesday of each month from 11:00 AM \u2013 12:00 PM EST/EDT. Here is the meeting link . View the calendar or subscribe ( Google Calendar , iCalendar file ). Feel free to bring discussion topics to the meeting. If you would like to present a demo, please drop us a note in the Iter8 Slack workspace . Our meetings are also recorded and publicly available on our YouTube channel .","title":"Meetings"},{"location":"community/community/#slack","text":"Iter8 Slack workspace is here . Join the Iter8 Slack for usage and development related discussions.","title":"Slack"},{"location":"community/community/#github-issues","text":"GitHub issues for all Iter8 repos are managed here .","title":"GitHub Issues"},{"location":"community/news/","text":"News and Announcements \u00b6 Feb 2022: The New Stack blog article on Simple HTTP Load Testing with SLOs Nov 2021: Iter8 at ACM Symposium on Cloud Computing. Full paper here Iter8 v0.7 and older Oct 2021: New Stack blog article by Hai Huang: Progressive Delivery on OpenShift Oct 2021: Iter8 at PREVAIL conference. Video coming soon. Conference details Oct 2021: New Stack blog article by Srinivasan Parthasarathy: Validate Service-Level Objectives of REST APIs Using Iter8 Jul 2021: Blog article by Clive Cox: ML\u200c \u200cProgressive\u200c \u200cRollouts\u200c \u200cwith\u200c \u200cSeldon\u200c \u200cand\u200c \u200cIter8\u200c Jul 2021: Iter8 at Knative meetup May 2021: Iter8 at KubeCon + CloudNativeCon Europe Mar 2021: Iter8 at Knative meetup Mar 2021: Kubeflow blog article by Animesh Singh and Dan Sun: Operationalize, Scale and Infuse Trust in AI Models using KFServing Oct 2020: Medium blog article by Michael Kalantar: Automated Canary Release of Microservices on Kubernetes using Tekton and iter8 Oct 2020: Medium blog article by Kusuma Chalasani: Better Performance with kruize and iter8 for your microservices application Oct 2020: Medium blog article by Srinivasan Parthasarathy: Automated Canary Release of TensorFlow Models on Kubernetes Oct 2020: Medium blog article by Sushma Ravichandran: Iter8: Take a look at the magic under the hood Aug 2020: Medium blog article by Fabio Oliveira: Iter8: Achieving Agility with Control","title":"News"},{"location":"community/news/#news-and-announcements","text":"Feb 2022: The New Stack blog article on Simple HTTP Load Testing with SLOs Nov 2021: Iter8 at ACM Symposium on Cloud Computing. Full paper here Iter8 v0.7 and older Oct 2021: New Stack blog article by Hai Huang: Progressive Delivery on OpenShift Oct 2021: Iter8 at PREVAIL conference. Video coming soon. Conference details Oct 2021: New Stack blog article by Srinivasan Parthasarathy: Validate Service-Level Objectives of REST APIs Using Iter8 Jul 2021: Blog article by Clive Cox: ML\u200c \u200cProgressive\u200c \u200cRollouts\u200c \u200cwith\u200c \u200cSeldon\u200c \u200cand\u200c \u200cIter8\u200c Jul 2021: Iter8 at Knative meetup May 2021: Iter8 at KubeCon + CloudNativeCon Europe Mar 2021: Iter8 at Knative meetup Mar 2021: Kubeflow blog article by Animesh Singh and Dan Sun: Operationalize, Scale and Infuse Trust in AI Models using KFServing Oct 2020: Medium blog article by Michael Kalantar: Automated Canary Release of Microservices on Kubernetes using Tekton and iter8 Oct 2020: Medium blog article by Kusuma Chalasani: Better Performance with kruize and iter8 for your microservices application Oct 2020: Medium blog article by Srinivasan Parthasarathy: Automated Canary Release of TensorFlow Models on Kubernetes Oct 2020: Medium blog article by Sushma Ravichandran: Iter8: Take a look at the magic under the hood Aug 2020: Medium blog article by Fabio Oliveira: Iter8: Achieving Agility with Control","title":"News and Announcements"},{"location":"getting-started/concepts/","text":"Iter8 \u00b6 Iter8 is the Kubernetes release optimizer built for DevOps, MLOps, SRE and data science teams. Iter8 makes it easy to ensure that Kubernetes apps and ML models perform well and maximize business value. Iter8 supports the following use-cases. Performance testing and SLO validation of HTTP services. Performance testing and SLO validation of gRPC services. SLO validation using custom metrics from any database(s) or REST API(s). Iter8 experiment \u00b6 Iter8 introduces the notion of an experiment, which is a list of configurable tasks that are executed in a specific sequence. Iter8 packs a number of powerful features that facilitate Kubernetes app testing and experimentation. They include the following. Generating load and collecting built-in metrics for HTTP and gRPC services. Simplifies performance testing by eliminating the need to setup and use metrics databases. Well-defined notion of service-level objectives (SLOs). Makes it simple to define and verify SLOs in experiments. Custom metrics. Enables the use of custom metrics from any database(s) or REST API(s) in experiments. Readiness check. The performance testing portion of the experiment begins only after the service is ready. HTML/text reports. Promotes human understanding of experiment results through visual insights. Assertions. Verifies whether the target app satisfies the specified SLOs or not after an experiment. Simplifies automation in CI/CD/GitOps pipelines: branch off into different paths depending upon whether the assertions are true or false. Multi-loop experiments. Experiment tasks can be executed periodically (multi-loop) instead of just once (single-loop). This enables Iter8 to refresh metric values and perform SLO validation using the latest metric values during each loop. Experiment anywhere. Iter8 experiments can be launched inside a Kubernetes cluster, in local environments, or inside a GitHub Actions pipeline. Kubernetes experiments \u00b6 Experiments that are executed inside Kubernetes clusters are referred to as Kubernetes experiments . All other experiments are referred to as local experiments . Runner \u00b6 A single-loop Kubernetes experiment uses the Kubernetes job workload as its runner. A multi-loop Kubernetes experiment uses the Kubernetes cronjob workload as its runner. Specifying an experiment \u00b6 Specifying an Iter8 experiment involves specifying the list of tasks executed during the experiment and their parameters . Additionally, Kubernetes experiments involve specifying the runner . Service-level objectives \u00b6 Service-level objectives (SLOs) are acceptable limits for an app's metric values. Both upper and lower limits on metric values can be specified as SLOs in Iter8 experiments. Implementation \u00b6 Iter8 is written in go and builds on a few awesome open source projects including: Helm Fortio ghz plotly.js","title":"Concepts"},{"location":"getting-started/concepts/#iter8","text":"Iter8 is the Kubernetes release optimizer built for DevOps, MLOps, SRE and data science teams. Iter8 makes it easy to ensure that Kubernetes apps and ML models perform well and maximize business value. Iter8 supports the following use-cases. Performance testing and SLO validation of HTTP services. Performance testing and SLO validation of gRPC services. SLO validation using custom metrics from any database(s) or REST API(s).","title":"Iter8"},{"location":"getting-started/concepts/#iter8-experiment","text":"Iter8 introduces the notion of an experiment, which is a list of configurable tasks that are executed in a specific sequence. Iter8 packs a number of powerful features that facilitate Kubernetes app testing and experimentation. They include the following. Generating load and collecting built-in metrics for HTTP and gRPC services. Simplifies performance testing by eliminating the need to setup and use metrics databases. Well-defined notion of service-level objectives (SLOs). Makes it simple to define and verify SLOs in experiments. Custom metrics. Enables the use of custom metrics from any database(s) or REST API(s) in experiments. Readiness check. The performance testing portion of the experiment begins only after the service is ready. HTML/text reports. Promotes human understanding of experiment results through visual insights. Assertions. Verifies whether the target app satisfies the specified SLOs or not after an experiment. Simplifies automation in CI/CD/GitOps pipelines: branch off into different paths depending upon whether the assertions are true or false. Multi-loop experiments. Experiment tasks can be executed periodically (multi-loop) instead of just once (single-loop). This enables Iter8 to refresh metric values and perform SLO validation using the latest metric values during each loop. Experiment anywhere. Iter8 experiments can be launched inside a Kubernetes cluster, in local environments, or inside a GitHub Actions pipeline.","title":"Iter8 experiment"},{"location":"getting-started/concepts/#kubernetes-experiments","text":"Experiments that are executed inside Kubernetes clusters are referred to as Kubernetes experiments . All other experiments are referred to as local experiments .","title":"Kubernetes experiments"},{"location":"getting-started/concepts/#runner","text":"A single-loop Kubernetes experiment uses the Kubernetes job workload as its runner. A multi-loop Kubernetes experiment uses the Kubernetes cronjob workload as its runner.","title":"Runner"},{"location":"getting-started/concepts/#specifying-an-experiment","text":"Specifying an Iter8 experiment involves specifying the list of tasks executed during the experiment and their parameters . Additionally, Kubernetes experiments involve specifying the runner .","title":"Specifying an experiment"},{"location":"getting-started/concepts/#service-level-objectives","text":"Service-level objectives (SLOs) are acceptable limits for an app's metric values. Both upper and lower limits on metric values can be specified as SLOs in Iter8 experiments.","title":"Service-level objectives"},{"location":"getting-started/concepts/#implementation","text":"Iter8 is written in go and builds on a few awesome open source projects including: Helm Fortio ghz plotly.js","title":"Implementation"},{"location":"getting-started/expreport/","text":"Text HTML iter8 k report The text report looks like this Experiment summary: ******************* Experiment completed: true No task failures: true Total number of tasks: 1 Number of completed tasks: 1 Latest observed values for metrics: *********************************** Metric | value ------- | ----- built-in/http-error-count | 0 .00 built-in/http-error-rate | 0 .00 built-in/http-latency-max ( msec ) | 203 .78 built-in/http-latency-mean ( msec ) | 17 .00 built-in/http-latency-min ( msec ) | 4 .20 built-in/http-latency-p50 ( msec ) | 10 .67 built-in/http-latency-p75 ( msec ) | 12 .33 built-in/http-latency-p90 ( msec ) | 14 .00 built-in/http-latency-p95 ( msec ) | 15 .67 built-in/http-latency-p99 ( msec ) | 202 .84 built-in/http-latency-p99.9 ( msec ) | 203 .69 built-in/http-latency-stddev ( msec ) | 37 .94 built-in/http-request-count | 100 .00 iter8 k report -o html > report.html # view in a browser The HTML report looks like this","title":"Expreport"},{"location":"getting-started/help/","text":"Get Help \u00b6 Read Iter8 docs . Join the Iter8 Slack workspace . File an issue or start a discussion on the Iter8 GitHub repo . Attend our community meetings! Follow Iter8 on Twitter .","title":"Get help"},{"location":"getting-started/help/#get-help","text":"Read Iter8 docs . Join the Iter8 Slack workspace . File an issue or start a discussion on the Iter8 GitHub repo . Attend our community meetings! Follow Iter8 on Twitter .","title":"Get Help"},{"location":"getting-started/install/","text":"Install Iter8 CLI \u00b6 Brew Binaries GitHub Actions Install the latest stable release of the Iter8 CLI using brew as follows. brew tap iter8-tools/iter8 brew install iter8@0.11 Install the latest stable release of the Iter8 CLI using a compressed binary tarball. darwin-amd64 (MacOS) linux-amd64 linux-386 windows-amd64 wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-darwin-amd64.tar.gz tar -xvf iter8-darwin-amd64.tar.gz Move darwin-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-amd64.tar.gz tar -xvf iter8-linux-amd64.tar.gz Move linux-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-386.tar.gz tar -xvf iter8-linux-386.tar.gz Move linux-386/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-windows-amd64.tar.gz tar -xvf iter8-windows-amd64.tar.gz Move windows-amd64/iter8.exe to any directory in your PATH . Install the latest stable release of the Iter8 CLI in your GitHub Actions workflow as follows. - uses : iter8-tools/iter8@v0.11","title":"Install Iter8"},{"location":"getting-started/install/#install-iter8-cli","text":"Brew Binaries GitHub Actions Install the latest stable release of the Iter8 CLI using brew as follows. brew tap iter8-tools/iter8 brew install iter8@0.11 Install the latest stable release of the Iter8 CLI using a compressed binary tarball. darwin-amd64 (MacOS) linux-amd64 linux-386 windows-amd64 wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-darwin-amd64.tar.gz tar -xvf iter8-darwin-amd64.tar.gz Move darwin-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-amd64.tar.gz tar -xvf iter8-linux-amd64.tar.gz Move linux-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-386.tar.gz tar -xvf iter8-linux-386.tar.gz Move linux-386/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-windows-amd64.tar.gz tar -xvf iter8-windows-amd64.tar.gz Move windows-amd64/iter8.exe to any directory in your PATH . Install the latest stable release of the Iter8 CLI in your GitHub Actions workflow as follows. - uses : iter8-tools/iter8@v0.11","title":"Install Iter8 CLI"},{"location":"getting-started/installbrewbins/","text":"Brew Binaries Install the latest stable release of the Iter8 CLI using brew as follows. brew tap iter8-tools/iter8 brew install iter8@0.11 Install the latest stable release of the Iter8 CLI using a compressed binary tarball. darwin-amd64 (MacOS) linux-amd64 linux-386 windows-amd64 wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-darwin-amd64.tar.gz tar -xvf iter8-darwin-amd64.tar.gz Move darwin-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-amd64.tar.gz tar -xvf iter8-linux-amd64.tar.gz Move linux-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-386.tar.gz tar -xvf iter8-linux-386.tar.gz Move linux-386/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-windows-amd64.tar.gz tar -xvf iter8-windows-amd64.tar.gz Move windows-amd64/iter8.exe to any directory in your PATH .","title":"Installbrewbins"},{"location":"getting-started/installghaction/","text":"GitHub Actions Install the latest stable release of the Iter8 CLI in your GitHub Actions workflow as follows. - uses : iter8-tools/iter8@v0.11","title":"Installghaction"},{"location":"getting-started/logs/","text":"Sample experiment logs INFO [ 2022 -06-27 11 :50:39 ] inited Helm config INFO [ 2022 -06-27 11 :50:39 ] experiment logs from Kubernetes cluster indented-trace = below ... time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 3 : http : started time = 2022 -06-27 15 :49:11 level = info msg = task 3 : http : completed time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : started time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : completed","title":"Logs"},{"location":"getting-started/your-first-experiment/","text":"Your First Experiment \u00b6 Run your first Iter8 experiment by load testing a Kubernetes HTTP service and validating its service-level objectives (SLOs) . This is a single-loop Kubernetes experiment . Before you begin Ensure that you have a Kubernetes cluster and the kubectl CLI . You can create a local Kubernetes cluster using tools like Kind or Minikube . Deploy the sample HTTP service in the Kubernetes cluster. kubectl create deploy httpbin --image = kennethreitz/httpbin --port = 80 kubectl expose deploy httpbin --port = 80 Install Iter8 CLI \u00b6 Brew Binaries Install the latest stable release of the Iter8 CLI using brew as follows. brew tap iter8-tools/iter8 brew install iter8@0.11 Install the latest stable release of the Iter8 CLI using a compressed binary tarball. darwin-amd64 (MacOS) linux-amd64 linux-386 windows-amd64 wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-darwin-amd64.tar.gz tar -xvf iter8-darwin-amd64.tar.gz Move darwin-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-amd64.tar.gz tar -xvf iter8-linux-amd64.tar.gz Move linux-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-386.tar.gz tar -xvf iter8-linux-386.tar.gz Move linux-386/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-windows-amd64.tar.gz tar -xvf iter8-windows-amd64.tar.gz Move windows-amd64/iter8.exe to any directory in your PATH . Launch experiment \u00b6 Launch the Iter8 experiment inside the Kubernetes cluster. iter8 k launch \\ --set \"tasks={ready,http,assess}\" \\ --set ready.deploy = httpbin \\ --set ready.service = httpbin \\ --set ready.timeout = 60s \\ --set http.url = http://httpbin.default/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 \\ --set runner = job About this experiment This experiment consists of three tasks , namely, ready , http , and assess . The ready task checks if the httpbin deployment exists and is available, and the httpbin service exists. The http task sends requests to the cluster-local HTTP service whose URL is http://httpbin.default/get , and collects Iter8's built-in HTTP load test metrics . The assess task verifies if the app satisfies the specified SLOs: i) the mean latency of the service does not exceed 50 msec, and ii) there are no errors (4xx or 5xx response codes) in the responses. This is a single-loop Kubernetes experiment where all the previously mentioned tasks will run once and the experiment will finish. Hence, its runner value is set to job . Some variations and extensions of this experiment The http task can be configured with load related parameters such as the number of requests, queries per second, or number of parallel connections. The http task can be configured to send various types of content as payload. The assess task can be configured with SLOs for any of Iter8's built-in HTTP load test metrics . This experiment can also be run in your local environment or run within a GitHub Actions pipeline . Assert experiment outcomes \u00b6 Assert that the experiment completed without failures, and all SLOs are satisfied. The timeout flag below specifies a period of 120 sec for assert conditions to be satisfied. iter8 k assert -c completed -c nofailure -c slos --timeout 120s If the assert conditions are satisfied, the above command exits with code 0; else, it exits with code 1. Assertions are especially useful inside CI/CD/GitOps pipelines. Depending on the exit code of the assert command, your pipeline can branch into different actions. View experiment report \u00b6 Text HTML iter8 k report The text report looks like this Experiment summary: ******************* Experiment completed: true No task failures: true Total number of tasks: 1 Number of completed tasks: 1 Latest observed values for metrics: *********************************** Metric | value ------- | ----- built-in/http-error-count | 0 .00 built-in/http-error-rate | 0 .00 built-in/http-latency-max ( msec ) | 203 .78 built-in/http-latency-mean ( msec ) | 17 .00 built-in/http-latency-min ( msec ) | 4 .20 built-in/http-latency-p50 ( msec ) | 10 .67 built-in/http-latency-p75 ( msec ) | 12 .33 built-in/http-latency-p90 ( msec ) | 14 .00 built-in/http-latency-p95 ( msec ) | 15 .67 built-in/http-latency-p99 ( msec ) | 202 .84 built-in/http-latency-p99.9 ( msec ) | 203 .69 built-in/http-latency-stddev ( msec ) | 37 .94 built-in/http-request-count | 100 .00 iter8 k report -o html > report.html # view in a browser The HTML report looks like this View experiment logs \u00b6 Logs are useful when debugging an experiment. iter8 k log Sample experiment logs INFO [ 2022 -06-27 11 :50:39 ] inited Helm config INFO [ 2022 -06-27 11 :50:39 ] experiment logs from Kubernetes cluster indented-trace = below ... time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 3 : http : started time = 2022 -06-27 15 :49:11 level = info msg = task 3 : http : completed time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : started time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : completed Cleanup \u00b6 Remove the Kubernetes objects created by the iter8 k launch command. iter8 k delete Congratulations! You completed your first Iter8 experiment.","title":"Your first experiment"},{"location":"getting-started/your-first-experiment/#your-first-experiment","text":"Run your first Iter8 experiment by load testing a Kubernetes HTTP service and validating its service-level objectives (SLOs) . This is a single-loop Kubernetes experiment . Before you begin Ensure that you have a Kubernetes cluster and the kubectl CLI . You can create a local Kubernetes cluster using tools like Kind or Minikube . Deploy the sample HTTP service in the Kubernetes cluster. kubectl create deploy httpbin --image = kennethreitz/httpbin --port = 80 kubectl expose deploy httpbin --port = 80","title":"Your First Experiment"},{"location":"getting-started/your-first-experiment/#install-iter8-cli","text":"Brew Binaries Install the latest stable release of the Iter8 CLI using brew as follows. brew tap iter8-tools/iter8 brew install iter8@0.11 Install the latest stable release of the Iter8 CLI using a compressed binary tarball. darwin-amd64 (MacOS) linux-amd64 linux-386 windows-amd64 wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-darwin-amd64.tar.gz tar -xvf iter8-darwin-amd64.tar.gz Move darwin-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-amd64.tar.gz tar -xvf iter8-linux-amd64.tar.gz Move linux-amd64/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-linux-386.tar.gz tar -xvf iter8-linux-386.tar.gz Move linux-386/iter8 to any directory in your PATH . wget https://github.com/iter8-tools/iter8/releases/latest/download/iter8-windows-amd64.tar.gz tar -xvf iter8-windows-amd64.tar.gz Move windows-amd64/iter8.exe to any directory in your PATH .","title":"Install Iter8 CLI"},{"location":"getting-started/your-first-experiment/#launch-experiment","text":"Launch the Iter8 experiment inside the Kubernetes cluster. iter8 k launch \\ --set \"tasks={ready,http,assess}\" \\ --set ready.deploy = httpbin \\ --set ready.service = httpbin \\ --set ready.timeout = 60s \\ --set http.url = http://httpbin.default/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 \\ --set runner = job About this experiment This experiment consists of three tasks , namely, ready , http , and assess . The ready task checks if the httpbin deployment exists and is available, and the httpbin service exists. The http task sends requests to the cluster-local HTTP service whose URL is http://httpbin.default/get , and collects Iter8's built-in HTTP load test metrics . The assess task verifies if the app satisfies the specified SLOs: i) the mean latency of the service does not exceed 50 msec, and ii) there are no errors (4xx or 5xx response codes) in the responses. This is a single-loop Kubernetes experiment where all the previously mentioned tasks will run once and the experiment will finish. Hence, its runner value is set to job . Some variations and extensions of this experiment The http task can be configured with load related parameters such as the number of requests, queries per second, or number of parallel connections. The http task can be configured to send various types of content as payload. The assess task can be configured with SLOs for any of Iter8's built-in HTTP load test metrics . This experiment can also be run in your local environment or run within a GitHub Actions pipeline .","title":"Launch experiment"},{"location":"getting-started/your-first-experiment/#assert-experiment-outcomes","text":"Assert that the experiment completed without failures, and all SLOs are satisfied. The timeout flag below specifies a period of 120 sec for assert conditions to be satisfied. iter8 k assert -c completed -c nofailure -c slos --timeout 120s If the assert conditions are satisfied, the above command exits with code 0; else, it exits with code 1. Assertions are especially useful inside CI/CD/GitOps pipelines. Depending on the exit code of the assert command, your pipeline can branch into different actions.","title":"Assert experiment outcomes"},{"location":"getting-started/your-first-experiment/#view-experiment-report","text":"Text HTML iter8 k report The text report looks like this Experiment summary: ******************* Experiment completed: true No task failures: true Total number of tasks: 1 Number of completed tasks: 1 Latest observed values for metrics: *********************************** Metric | value ------- | ----- built-in/http-error-count | 0 .00 built-in/http-error-rate | 0 .00 built-in/http-latency-max ( msec ) | 203 .78 built-in/http-latency-mean ( msec ) | 17 .00 built-in/http-latency-min ( msec ) | 4 .20 built-in/http-latency-p50 ( msec ) | 10 .67 built-in/http-latency-p75 ( msec ) | 12 .33 built-in/http-latency-p90 ( msec ) | 14 .00 built-in/http-latency-p95 ( msec ) | 15 .67 built-in/http-latency-p99 ( msec ) | 202 .84 built-in/http-latency-p99.9 ( msec ) | 203 .69 built-in/http-latency-stddev ( msec ) | 37 .94 built-in/http-request-count | 100 .00 iter8 k report -o html > report.html # view in a browser The HTML report looks like this","title":"View experiment report"},{"location":"getting-started/your-first-experiment/#view-experiment-logs","text":"Logs are useful when debugging an experiment. iter8 k log Sample experiment logs INFO [ 2022 -06-27 11 :50:39 ] inited Helm config INFO [ 2022 -06-27 11 :50:39 ] experiment logs from Kubernetes cluster indented-trace = below ... time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 1 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : started time = 2022 -06-27 15 :48:59 level = info msg = task 2 : ready : completed time = 2022 -06-27 15 :48:59 level = info msg = task 3 : http : started time = 2022 -06-27 15 :49:11 level = info msg = task 3 : http : completed time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : started time = 2022 -06-27 15 :49:11 level = info msg = task 4 : assess : completed","title":"View experiment logs"},{"location":"getting-started/your-first-experiment/#cleanup","text":"Remove the Kubernetes objects created by the iter8 k launch command. iter8 k delete Congratulations! You completed your first Iter8 experiment.","title":"Cleanup"},{"location":"metrics/custom-metrics/","text":"Custom Metrics \u00b6 Custom Iter8 metrics enable you to use data from any database for evaluating app/ML model versions within Iter8 experiments. This document describes how you can define custom Iter8 metrics and (optionally) supply authentication information that may be required by the metrics provider. Metric providers differ in the following aspects. HTTP request authentication method: no authentication, basic auth, API keys, or bearer token HTTP request method: GET or POST Format of HTTP parameters and/or JSON body used while querying them Format of the JSON response returned by the provider The logic used by Iter8 to extract the metric value from the JSON response The examples in this document focus on Prometheus, NewRelic, Sysdig, and Elastic. However, the principles illustrated here will enable you to use metrics from any provider in experiments. Metrics with/without auth \u00b6 Note: Metrics are defined by you, the Iter8 end-user . Prometheus Prometheus does not support any authentication mechanism out-of-the-box . However, Prometheus can be setup in conjunction with a reverse proxy, which in turn can support HTTP request authentication, as described here . No Authentication The following is an example of an Iter8 metric with Prometheus as the provider. This example assumes that Prometheus can be queried by Iter8 without any authentication. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 url : http://127.0.0.1:9090/api/v1/query provider : istio method : GET metrics : - name : request-count type : counter description : | Number of requests params : - name : query value : | sum(last_over_time(istio_requests_total{ reporter=\"source\", {{- if .destination_workload }} destination_workload=\"{{.destination_workload}}\", {{- end }} {{- if .destination_workload_namespace }} destination_workload_namespace=\"{{.destination_workload_namespace}}\", {{- end }} }[{{.elapsedTimeSeconds}}s])) or on() vector(0) jqExpression : .data.result[0].value[1] Brief explanation of the request-count metric The HTTP query used by Iter8 contains a single query parameter named query as required by Prometheus . The value of this parameter is derived by substituting the placeholders in the value string. The url field provides the URL of the Prometheus service. The method field provides the HTTP method, in this case GET . The jqExpression enables Iter8 to extract the metric value from the JSON response returned by Prometheus. Placeholder substitution \u00b6 Note: This step is automated by Iter8 . Prometheus The placeholder elapsedTimeSeconds is substituted based on the start of the experiment or startingTime , if provided in the CLI. If startingTime is provided, then the time should follow RFC 3339 (for example: 2020-02-01T09:44:40Z or 2020-02-01T09:44:40.954641934Z ). JSON response \u00b6 Note: This step is handled by the metrics provider . The metrics provider is expected to respond to Iter8's HTTP request with a JSON object. The format of this JSON object is defined by the provider. Prometheus The format of the Prometheus JSON response is defined here . A sample Prometheus response is as follows. 1 2 3 4 5 6 7 8 9 10 11 { \"status\" : \"success\" , \"data\" : { \"resultType\" : \"vector\" , \"result\" : [ { \"value\" : [ 1556823494.744 , \"21.7639\" ] } ] } } Processing the JSON response \u00b6 Note: This step is automated by Iter8 . Iter8 uses jq to extract the metric value from the JSON response of the provider. The jqExpression used by Iter8 is supplied as part of the metric definition. When the jqExpression is applied to the JSON response, it is expected to yield a number. Prometheus Consider the jqExpression defined in the sample Prometheus metric . Let us apply it to the sample JSON response from Prometheus . echo '{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"value\": [1556823494.744, \"21.7639\"] } ] } }' | jq \".data.result[0].value[1] | tonumber\" Executing the above command results yields 21.7639 , a number, as required by Iter8. Note: The shell command above is for illustration only. Iter8 uses Python bindings for jq to evaluate the jqExpression . Error handling \u00b6 Note: This step is automated by Iter8 . Errors may occur during Iter8's metric queries due to a number of reasons (for example, due to an invalid jqExpression supplied within the metric). If Iter8 encounters errors during its attempt to retrieve metric values, Iter8 will mark the respective metric as unavailable. Iter8 can be used with any provider that can receive an HTTP request and respond with a JSON object containing the metrics information. Documentation requests and contributions (PRs) are welcome for providers not listed here. \u21a9","title":"Custom Metrics"},{"location":"metrics/custom-metrics/#custom-metrics","text":"Custom Iter8 metrics enable you to use data from any database for evaluating app/ML model versions within Iter8 experiments. This document describes how you can define custom Iter8 metrics and (optionally) supply authentication information that may be required by the metrics provider. Metric providers differ in the following aspects. HTTP request authentication method: no authentication, basic auth, API keys, or bearer token HTTP request method: GET or POST Format of HTTP parameters and/or JSON body used while querying them Format of the JSON response returned by the provider The logic used by Iter8 to extract the metric value from the JSON response The examples in this document focus on Prometheus, NewRelic, Sysdig, and Elastic. However, the principles illustrated here will enable you to use metrics from any provider in experiments.","title":"Custom Metrics"},{"location":"metrics/custom-metrics/#metrics-withwithout-auth","text":"Note: Metrics are defined by you, the Iter8 end-user . Prometheus Prometheus does not support any authentication mechanism out-of-the-box . However, Prometheus can be setup in conjunction with a reverse proxy, which in turn can support HTTP request authentication, as described here . No Authentication The following is an example of an Iter8 metric with Prometheus as the provider. This example assumes that Prometheus can be queried by Iter8 without any authentication. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 url : http://127.0.0.1:9090/api/v1/query provider : istio method : GET metrics : - name : request-count type : counter description : | Number of requests params : - name : query value : | sum(last_over_time(istio_requests_total{ reporter=\"source\", {{- if .destination_workload }} destination_workload=\"{{.destination_workload}}\", {{- end }} {{- if .destination_workload_namespace }} destination_workload_namespace=\"{{.destination_workload_namespace}}\", {{- end }} }[{{.elapsedTimeSeconds}}s])) or on() vector(0) jqExpression : .data.result[0].value[1] Brief explanation of the request-count metric The HTTP query used by Iter8 contains a single query parameter named query as required by Prometheus . The value of this parameter is derived by substituting the placeholders in the value string. The url field provides the URL of the Prometheus service. The method field provides the HTTP method, in this case GET . The jqExpression enables Iter8 to extract the metric value from the JSON response returned by Prometheus.","title":"Metrics with/without auth"},{"location":"metrics/custom-metrics/#placeholder-substitution","text":"Note: This step is automated by Iter8 . Prometheus The placeholder elapsedTimeSeconds is substituted based on the start of the experiment or startingTime , if provided in the CLI. If startingTime is provided, then the time should follow RFC 3339 (for example: 2020-02-01T09:44:40Z or 2020-02-01T09:44:40.954641934Z ).","title":"Placeholder substitution"},{"location":"metrics/custom-metrics/#json-response","text":"Note: This step is handled by the metrics provider . The metrics provider is expected to respond to Iter8's HTTP request with a JSON object. The format of this JSON object is defined by the provider. Prometheus The format of the Prometheus JSON response is defined here . A sample Prometheus response is as follows. 1 2 3 4 5 6 7 8 9 10 11 { \"status\" : \"success\" , \"data\" : { \"resultType\" : \"vector\" , \"result\" : [ { \"value\" : [ 1556823494.744 , \"21.7639\" ] } ] } }","title":"JSON response"},{"location":"metrics/custom-metrics/#processing-the-json-response","text":"Note: This step is automated by Iter8 . Iter8 uses jq to extract the metric value from the JSON response of the provider. The jqExpression used by Iter8 is supplied as part of the metric definition. When the jqExpression is applied to the JSON response, it is expected to yield a number. Prometheus Consider the jqExpression defined in the sample Prometheus metric . Let us apply it to the sample JSON response from Prometheus . echo '{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"value\": [1556823494.744, \"21.7639\"] } ] } }' | jq \".data.result[0].value[1] | tonumber\" Executing the above command results yields 21.7639 , a number, as required by Iter8. Note: The shell command above is for illustration only. Iter8 uses Python bindings for jq to evaluate the jqExpression .","title":"Processing the JSON response"},{"location":"metrics/custom-metrics/#error-handling","text":"Note: This step is automated by Iter8 . Errors may occur during Iter8's metric queries due to a number of reasons (for example, due to an invalid jqExpression supplied within the metric). If Iter8 encounters errors during its attempt to retrieve metric values, Iter8 will mark the respective metric as unavailable. Iter8 can be used with any provider that can receive an HTTP request and respond with a JSON object containing the metrics information. Documentation requests and contributions (PRs) are welcome for providers not listed here. \u21a9","title":"Error handling"},{"location":"tutorials/load-test-grpc/","text":"Load Test gRPC with SLOs \u00b6 Load test a Kubernetes gRPC service and validate its service-level objectives (SLOs) . This is a single-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Deploy the sample gRPC service in the Kubernetes cluster. kubectl create deploy hello --image = docker.io/grpc/java-example-hostname:latest --port = 50051 kubectl expose deploy hello --port = 50051 Launch experiment \u00b6 iter8 k launch \\ --set \"tasks={ready,grpc,assess}\" \\ --set ready.deploy = hello \\ --set ready.service = hello \\ --set ready.timeout = 60s \\ --set grpc.host = \"hello.default:50051\" \\ --set grpc.call = \"helloworld.Greeter.SayHello\" \\ --set grpc.protoURL = \"https://raw.githubusercontent.com/grpc/grpc-go/master/examples/helloworld/helloworld/helloworld.proto\" \\ --set assess.SLOs.upper.grpc/error-rate = 0 \\ --set assess.SLOs.upper.grpc/latency/mean = 200 \\ --set assess.SLOs.upper.grpc/latency/p '97\\.5' = 800 \\ --set runner = job About this experiment This experiment consists of three tasks , namely, ready , grpc , and assess . The ready task checks if the hello deployment exists and is available, and the hello service exists. The grpc task sends call requests to the helloworld.Greeter.SayHello method of the cluster-local gRPC service with host address hello.default:50051 , and collects Iter8's built-in gRPC load test metrics . The assess task verifies if the app satisfies the specified SLOs: i) there are no errors, ii) the mean latency of the service does not exceed 50 msec, and iii) the 97.5 th percentile latency does not exceed 200 msec. This is a single-loop Kubernetes experiment where all the previously mentioned tasks will run once and the experiment will finish. Hence, its runner value is set to job . Some variations and extensions of this experiment The grpc task can be configured with load related parameters such as the total number of requests, requests per second, or number of concurrent connections. The grpc task can be configured to JSON or binary data as payload. You can use this task to test unary or streaming gRPC methods. The assess task can be configured with SLOs for any of Iter8's built-in grpc load test metrics . This experiment can also be run in your local environment or run within a GitHub Actions pipeline . Assert experiment outcomes, view experiment report, view experiment logs, and cleanup as described in your first experiment .","title":"Load test gRPC with SLOs"},{"location":"tutorials/load-test-grpc/#load-test-grpc-with-slos","text":"Load test a Kubernetes gRPC service and validate its service-level objectives (SLOs) . This is a single-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Deploy the sample gRPC service in the Kubernetes cluster. kubectl create deploy hello --image = docker.io/grpc/java-example-hostname:latest --port = 50051 kubectl expose deploy hello --port = 50051","title":"Load Test gRPC with SLOs"},{"location":"tutorials/load-test-grpc/#launch-experiment","text":"iter8 k launch \\ --set \"tasks={ready,grpc,assess}\" \\ --set ready.deploy = hello \\ --set ready.service = hello \\ --set ready.timeout = 60s \\ --set grpc.host = \"hello.default:50051\" \\ --set grpc.call = \"helloworld.Greeter.SayHello\" \\ --set grpc.protoURL = \"https://raw.githubusercontent.com/grpc/grpc-go/master/examples/helloworld/helloworld/helloworld.proto\" \\ --set assess.SLOs.upper.grpc/error-rate = 0 \\ --set assess.SLOs.upper.grpc/latency/mean = 200 \\ --set assess.SLOs.upper.grpc/latency/p '97\\.5' = 800 \\ --set runner = job About this experiment This experiment consists of three tasks , namely, ready , grpc , and assess . The ready task checks if the hello deployment exists and is available, and the hello service exists. The grpc task sends call requests to the helloworld.Greeter.SayHello method of the cluster-local gRPC service with host address hello.default:50051 , and collects Iter8's built-in gRPC load test metrics . The assess task verifies if the app satisfies the specified SLOs: i) there are no errors, ii) the mean latency of the service does not exceed 50 msec, and iii) the 97.5 th percentile latency does not exceed 200 msec. This is a single-loop Kubernetes experiment where all the previously mentioned tasks will run once and the experiment will finish. Hence, its runner value is set to job . Some variations and extensions of this experiment The grpc task can be configured with load related parameters such as the total number of requests, requests per second, or number of concurrent connections. The grpc task can be configured to JSON or binary data as payload. You can use this task to test unary or streaming gRPC methods. The assess task can be configured with SLOs for any of Iter8's built-in grpc load test metrics . This experiment can also be run in your local environment or run within a GitHub Actions pipeline . Assert experiment outcomes, view experiment report, view experiment logs, and cleanup as described in your first experiment .","title":"Launch experiment"},{"location":"tutorials/load-test-http/","text":"Load Test HTTP with SLOs \u00b6 Your first experiment describes how to load test an HTTP service inside Kubernetes and validate its SLOs .","title":"Load test HTTP with SLOs"},{"location":"tutorials/load-test-http/#load-test-http-with-slos","text":"Your first experiment describes how to load test an HTTP service inside Kubernetes and validate its SLOs .","title":"Load Test HTTP with SLOs"},{"location":"tutorials/custom-metrics/assert/","text":"Assert that the experiment encountered no failures, and all SLOs are satisfied. iter8 k assert -c nofailure -c slos Sample output from assert INFO [ 2021 -11-10 09 :33:12 ] experiment has no failure INFO [ 2021 -11-10 09 :33:12 ] SLOs are satisfied INFO [ 2021 -11-10 09 :33:12 ] all conditions were satisfied","title":"Assert"},{"location":"tutorials/custom-metrics/one-version/","text":"SLO validation using custom metrics (single version) \u00b6 Validate SLOs for an app by fetching the app's metrics from a database (like Prometheus). This is a multi-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Install Istio . Install Istio's Prometheus add-on . Enable automatic Istio sidecar injection for the default namespace. This ensures that the pods created in steps 5 and 6 will have the Istio sidecar. kubectl label namespace default istio-injection = enabled --overwrite Deploy the sample HTTP service in the Kubernetes cluster. kubectl create deploy httpbin --image = kennethreitz/httpbin --port = 80 kubectl expose deploy httpbin --port = 80 Generate load. kubectl run fortio --image = fortio/fortio --command -- fortio load -t 6000s http://httpbin.default/get Launch experiment \u00b6 iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkload = httpbin \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" About this experiment This experiment consists of two tasks , namely, custommetrics , and assess . The custommetrics task in this experiment works by downloading a provider template named istio-prom from a URL, substituting the template variables with values , using the resulting provider spec to query Prometheus for metrics, and processing the response from Prometheus to extract the metric values. Metrics defined by this template include error-rate and latency-mean ; variables used by this template include destinationWorkload and destinationWorkloadNamespace ; all the metrics and variables associated with this template are documented as part of the template . The assess task verifies if the app satisfies the specified SLOs: i) there are no errors, and ii) the mean latency of the app does not exceed 100 msec. This is a multi-loop Kubernetes experiment . Hence, its runner value is set to cronjob . The cronjobSchedule expression specifies that each experiment loop (i.e., the sequence of tasks in the experiment) is scheduled for execution periodically once every minute. This enables Iter8 to refresh the metric values and perform SLO validation using the latest metric values during each loop. Some variations and extensions of this experiment Perform SLO validation for multiple versions of an app using custom metrics . Define and use your own provider templates. This enables you to use any app-specific metrics from any database as part of Iter8 experiments. Read the documentation for the custommetrics task to learn more. Alter the cronjobSchedule expression so that experiment loops are repeated at a frequency of your choice. Use use https://crontab.guru to learn more about cronjobSchedule expressions. Assert experiment outcomes \u00b6 Assert that the experiment encountered no failures, and all SLOs are satisfied. iter8 k assert -c nofailure -c slos Sample output from assert INFO [ 2021 -11-10 09 :33:12 ] experiment has no failure INFO [ 2021 -11-10 09 :33:12 ] SLOs are satisfied INFO [ 2021 -11-10 09 :33:12 ] all conditions were satisfied View experiment report and logs, and cleanup as described in your first experiment .","title":"One version"},{"location":"tutorials/custom-metrics/one-version/#slo-validation-using-custom-metrics-single-version","text":"Validate SLOs for an app by fetching the app's metrics from a database (like Prometheus). This is a multi-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Install Istio . Install Istio's Prometheus add-on . Enable automatic Istio sidecar injection for the default namespace. This ensures that the pods created in steps 5 and 6 will have the Istio sidecar. kubectl label namespace default istio-injection = enabled --overwrite Deploy the sample HTTP service in the Kubernetes cluster. kubectl create deploy httpbin --image = kennethreitz/httpbin --port = 80 kubectl expose deploy httpbin --port = 80 Generate load. kubectl run fortio --image = fortio/fortio --command -- fortio load -t 6000s http://httpbin.default/get","title":"SLO validation using custom metrics (single version)"},{"location":"tutorials/custom-metrics/one-version/#launch-experiment","text":"iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkload = httpbin \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" About this experiment This experiment consists of two tasks , namely, custommetrics , and assess . The custommetrics task in this experiment works by downloading a provider template named istio-prom from a URL, substituting the template variables with values , using the resulting provider spec to query Prometheus for metrics, and processing the response from Prometheus to extract the metric values. Metrics defined by this template include error-rate and latency-mean ; variables used by this template include destinationWorkload and destinationWorkloadNamespace ; all the metrics and variables associated with this template are documented as part of the template . The assess task verifies if the app satisfies the specified SLOs: i) there are no errors, and ii) the mean latency of the app does not exceed 100 msec. This is a multi-loop Kubernetes experiment . Hence, its runner value is set to cronjob . The cronjobSchedule expression specifies that each experiment loop (i.e., the sequence of tasks in the experiment) is scheduled for execution periodically once every minute. This enables Iter8 to refresh the metric values and perform SLO validation using the latest metric values during each loop. Some variations and extensions of this experiment Perform SLO validation for multiple versions of an app using custom metrics . Define and use your own provider templates. This enables you to use any app-specific metrics from any database as part of Iter8 experiments. Read the documentation for the custommetrics task to learn more. Alter the cronjobSchedule expression so that experiment loops are repeated at a frequency of your choice. Use use https://crontab.guru to learn more about cronjobSchedule expressions.","title":"Launch experiment"},{"location":"tutorials/custom-metrics/one-version/#assert-experiment-outcomes","text":"Assert that the experiment encountered no failures, and all SLOs are satisfied. iter8 k assert -c nofailure -c slos Sample output from assert INFO [ 2021 -11-10 09 :33:12 ] experiment has no failure INFO [ 2021 -11-10 09 :33:12 ] SLOs are satisfied INFO [ 2021 -11-10 09 :33:12 ] all conditions were satisfied View experiment report and logs, and cleanup as described in your first experiment .","title":"Assert experiment outcomes"},{"location":"tutorials/custom-metrics/two-or-more-versions/","text":"SLO validation using custom metrics (multiple versions) \u00b6 Validate SLOs for multiple versions of an app by fetching metrics for each app version from a database (like Prometheus). This is a multi-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Try an SLO validation experiment using custom metrics for a single version of an app . Complete the Istio traffic mirroring tutorial , specifically, the setup steps , the step for creating the default routing policy , and the step for mirroring traffic . Omit the step for cleaning up (you can clean up once you are done with this tutorial). Install Istio's Prometheus add-on . Generate load. kubectl run fortio --image = fortio/fortio --command -- fortio load -t 6000s http://httpbin.default:8000/get Launch experiment \u00b6 iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set custommetrics.values.reporter = destination \\ --set custommetrics.versionValues [ 0 ] .destinationWorkload = httpbin-v1 \\ --set custommetrics.versionValues [ 1 ] .destinationWorkload = httpbin-v2 \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" About this experiment This experiment extends the SLO validation experiment using custom metrics for a single app version . There are two versions of the app in this experiment. Variable values that are specific to the first version are specified under custommetrics.versionValues[0] , while those that are specific to the second version are specified under custommetrics.versionValues[1] . For the first version, Iter8 merges custommetrics.values with custommetrics.versionValues[0] (the latter takes precedence), and uses the result for template variable substitution. Similarly, for the second version, Iter8 merges custommetrics.values with custommetrics.versionValues[1] (the latter takes precedence), and uses the result for template variable substitution. Some variations and extensions of this experiment Define and use your own provider templates. This enables you to use any app-specific metrics from any database as part of Iter8 experiments. Read the documentation for the custommetrics task to learn more. Alter the cronjobSchedule expression so that experiment loops are repeated at a frequency of your choice. Use use https://crontab.guru to learn more about cronjobSchedule expressions. Assert experiment outcomes, view experiment report, view experiment logs, and cleanup as described in this experiment .","title":"Two or more versions"},{"location":"tutorials/custom-metrics/two-or-more-versions/#slo-validation-using-custom-metrics-multiple-versions","text":"Validate SLOs for multiple versions of an app by fetching metrics for each app version from a database (like Prometheus). This is a multi-loop Kubernetes experiment . Before you begin Try your first experiment . Understand the main concepts behind Iter8 experiments. Try an SLO validation experiment using custom metrics for a single version of an app . Complete the Istio traffic mirroring tutorial , specifically, the setup steps , the step for creating the default routing policy , and the step for mirroring traffic . Omit the step for cleaning up (you can clean up once you are done with this tutorial). Install Istio's Prometheus add-on . Generate load. kubectl run fortio --image = fortio/fortio --command -- fortio load -t 6000s http://httpbin.default:8000/get","title":"SLO validation using custom metrics (multiple versions)"},{"location":"tutorials/custom-metrics/two-or-more-versions/#launch-experiment","text":"iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set custommetrics.values.reporter = destination \\ --set custommetrics.versionValues [ 0 ] .destinationWorkload = httpbin-v1 \\ --set custommetrics.versionValues [ 1 ] .destinationWorkload = httpbin-v2 \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" About this experiment This experiment extends the SLO validation experiment using custom metrics for a single app version . There are two versions of the app in this experiment. Variable values that are specific to the first version are specified under custommetrics.versionValues[0] , while those that are specific to the second version are specified under custommetrics.versionValues[1] . For the first version, Iter8 merges custommetrics.values with custommetrics.versionValues[0] (the latter takes precedence), and uses the result for template variable substitution. Similarly, for the second version, Iter8 merges custommetrics.values with custommetrics.versionValues[1] (the latter takes precedence), and uses the result for template variable substitution. Some variations and extensions of this experiment Define and use your own provider templates. This enables you to use any app-specific metrics from any database as part of Iter8 experiments. Read the documentation for the custommetrics task to learn more. Alter the cronjobSchedule expression so that experiment loops are repeated at a frequency of your choice. Use use https://crontab.guru to learn more about cronjobSchedule expressions. Assert experiment outcomes, view experiment report, view experiment logs, and cleanup as described in this experiment .","title":"Launch experiment"},{"location":"tutorials/integrations/ghactions/","text":"Use Iter8 in a GitHub Actions workflow \u00b6 Install the latest version of the Iter8 CLI using iter8-tools/iter8@v0.11 . Once installed, the Iter8 CLI can be used as documented in various tutorials. For example: 1 2 3 4 5 6 7 8 9 10 11 12 # install Iter8 CLI - uses : iter8-tools/iter8@v0.11 # launch a local experiment - run : | iter8 launch --set \"tasks={http}\" --set http.url=http://httpbin.org/get # launch an experiment inside Kubernetes; # this assumes that your Kubernetes cluster is accessible # from the GitHub Actions pipeline - run : | iter8 k launch --set \"tasks={http}\" \\ --set http.url=http://httpbin.org/get \\ --set runner=job","title":"GitHub Actions"},{"location":"tutorials/integrations/ghactions/#use-iter8-in-a-github-actions-workflow","text":"Install the latest version of the Iter8 CLI using iter8-tools/iter8@v0.11 . Once installed, the Iter8 CLI can be used as documented in various tutorials. For example: 1 2 3 4 5 6 7 8 9 10 11 12 # install Iter8 CLI - uses : iter8-tools/iter8@v0.11 # launch a local experiment - run : | iter8 launch --set \"tasks={http}\" --set http.url=http://httpbin.org/get # launch an experiment inside Kubernetes; # this assumes that your Kubernetes cluster is accessible # from the GitHub Actions pipeline - run : | iter8 k launch --set \"tasks={http}\" \\ --set http.url=http://httpbin.org/get \\ --set runner=job","title":"Use Iter8 in a GitHub Actions workflow"},{"location":"tutorials/integrations/istio/","text":"SLO Validation using Istio's Prometheus Add-on \u00b6 SLO validation using Istio's Prometheus add-on SLO validation using Istio's Prometheus add-on with traffic mirroring Istio Examples based on Iter8 v0.7 \u00b6 Hybrid (A/B + SLOs) testing SLO validation SLO validation (single version) Progressive traffic shifting Fixed % split","title":"Istio"},{"location":"tutorials/integrations/istio/#slo-validation-using-istios-prometheus-add-on","text":"SLO validation using Istio's Prometheus add-on SLO validation using Istio's Prometheus add-on with traffic mirroring","title":"SLO Validation using Istio's Prometheus Add-on"},{"location":"tutorials/integrations/istio/#istio-examples-based-on-iter8-v07","text":"Hybrid (A/B + SLOs) testing SLO validation SLO validation (single version) Progressive traffic shifting Fixed % split","title":"Istio Examples based on Iter8 v0.7"},{"location":"tutorials/integrations/knative/","text":"Knative blog article on performance testing of HTTP and gRPC services with SLO validation using Iter8.","title":"Knative"},{"location":"tutorials/integrations/kserve/","text":"KServe Examples based on Iter8 v0.7 \u00b6 A/B Testing and Progressive Traffic Shift Hybrid (A/B + SLOs) testing Progressive traffic shifting Fixed-%-split Session affinity","title":"Kserve"},{"location":"tutorials/integrations/kserve/#kserve-examples-based-on-iter8-v07","text":"A/B Testing and Progressive Traffic Shift Hybrid (A/B + SLOs) testing Progressive traffic shifting Fixed-%-split Session affinity","title":"KServe Examples based on Iter8 v0.7"},{"location":"tutorials/integrations/linkerd/","text":"Linkerd Examples based on Iter8 v0.7 \u00b6 A/B testing","title":"Linkerd"},{"location":"tutorials/integrations/linkerd/#linkerd-examples-based-on-iter8-v07","text":"A/B testing","title":"Linkerd Examples based on Iter8 v0.7"},{"location":"tutorials/integrations/litmus/","text":"Litmus Chaos Examples based on Iter8 v0.7 \u00b6 SLO Validation with Chaos","title":"Litmus"},{"location":"tutorials/integrations/litmus/#litmus-chaos-examples-based-on-iter8-v07","text":"SLO Validation with Chaos","title":"Litmus Chaos Examples based on Iter8 v0.7"},{"location":"tutorials/integrations/local/","text":"Running experiments in the local environment \u00b6 Iter8 can be used to run experiments in the local environment as in the following example. In contrast to Kubernetes experiment launch, the local launch does not use the k subcommand. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url = https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 Local experiments are useful for development and debugging. Further, assuming that the HTTP and gRPC services can be reached from the local environment, they can be tested using local experiments even without access to the cluster where they may be hosted. Use the iter8 assert and iter8 report commands (without the k subcommand) to assert and report results from local experiments.","title":"Local environment"},{"location":"tutorials/integrations/local/#running-experiments-in-the-local-environment","text":"Iter8 can be used to run experiments in the local environment as in the following example. In contrast to Kubernetes experiment launch, the local launch does not use the k subcommand. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url = https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 Local experiments are useful for development and debugging. Further, assuming that the HTTP and gRPC services can be reached from the local environment, they can be tested using local experiments even without access to the cluster where they may be hosted. Use the iter8 assert and iter8 report commands (without the k subcommand) to assert and report results from local experiments.","title":"Running experiments in the local environment"},{"location":"tutorials/integrations/overview/","text":"Integrations \u00b6 The tutorials under the integrations section are maintained by members of the Iter8 community. They may become outdated. If you find that something is not working, please lend a helping hand and fix it in a PR. More integrations and examples are always welcome.","title":"Integrations"},{"location":"tutorials/integrations/overview/#integrations","text":"The tutorials under the integrations section are maintained by members of the Iter8 community. They may become outdated. If you find that something is not working, please lend a helping hand and fix it in a PR. More integrations and examples are always welcome.","title":"Integrations"},{"location":"tutorials/integrations/seldon/","text":"Seldon Examples based on Iter8 v0.7 \u00b6 Hybrid (A/B + SLOs) testing Progressive traffic shifting","title":"Seldon"},{"location":"tutorials/integrations/seldon/#seldon-examples-based-on-iter8-v07","text":"Hybrid (A/B + SLOs) testing Progressive traffic shifting","title":"Seldon Examples based on Iter8 v0.7"},{"location":"user-guide/commands/iter8/","text":"iter8 \u00b6 Kubernetes release optimizer Synopsis \u00b6 Iter8 is the Kubernetes release optimizer built for DevOps, MLOps, SRE and data science teams. Iter8 makes it easy to ensure that Kubernetes apps and ML models perform well and maximize business value. Options \u00b6 -h, --help help for iter8 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 assert - Assert if experiment result satisfies conditions iter8 gen - Generate experiment.yaml file by combining an experiment chart with values iter8 hub - Download Iter8 experiment chart iter8 k - Work with Kubernetes experiments iter8 launch - Launch an experiment in the local environment iter8 report - Generate experiment report iter8 run - Run an experiment iter8 version - Print Iter8 CLI version Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8"},{"location":"user-guide/commands/iter8/#iter8","text":"Kubernetes release optimizer","title":"iter8"},{"location":"user-guide/commands/iter8/#synopsis","text":"Iter8 is the Kubernetes release optimizer built for DevOps, MLOps, SRE and data science teams. Iter8 makes it easy to ensure that Kubernetes apps and ML models perform well and maximize business value.","title":"Synopsis"},{"location":"user-guide/commands/iter8/#options","text":"-h, --help help for iter8 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options"},{"location":"user-guide/commands/iter8/#see-also","text":"iter8 assert - Assert if experiment result satisfies conditions iter8 gen - Generate experiment.yaml file by combining an experiment chart with values iter8 hub - Download Iter8 experiment chart iter8 k - Work with Kubernetes experiments iter8 launch - Launch an experiment in the local environment iter8 report - Generate experiment report iter8 run - Run an experiment iter8 version - Print Iter8 CLI version","title":"SEE ALSO"},{"location":"user-guide/commands/iter8/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_assert/","text":"iter8 assert \u00b6 Assert if experiment result satisfies conditions Synopsis \u00b6 Assert if the result of an experiment satisfies the specified conditions. If all conditions are satisfied, the command exits with code 0. Else, the command exits with code 1. Assertions are especially useful for automation inside CI/CD/GitOps pipelines. Supported conditions are 'completed', 'nofailure', 'slos', which indicate that the experiment has completed, none of the tasks have failed, and the SLOs are satisfied. iter8 assert -c completed -c nofailure -c slos # same as iter8 assert -c completed,nofailure,slos You can optionally specify a timeout, which is the maximum amount of time to wait for the conditions to be satisfied: iter8 assert -c completed,nofailure,slos -t 5s iter8 assert [flags] Options \u00b6 -c, --condition strings completed | nofailure | slos; can specify multiple or separate conditions with commas; -h, --help help for assert --runDir string directory where experiment is run; contains experiment.yaml (default \".\") --timeout duration timeout duration (e.g., 5s) Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 assert"},{"location":"user-guide/commands/iter8_assert/#iter8-assert","text":"Assert if experiment result satisfies conditions","title":"iter8 assert"},{"location":"user-guide/commands/iter8_assert/#synopsis","text":"Assert if the result of an experiment satisfies the specified conditions. If all conditions are satisfied, the command exits with code 0. Else, the command exits with code 1. Assertions are especially useful for automation inside CI/CD/GitOps pipelines. Supported conditions are 'completed', 'nofailure', 'slos', which indicate that the experiment has completed, none of the tasks have failed, and the SLOs are satisfied. iter8 assert -c completed -c nofailure -c slos # same as iter8 assert -c completed,nofailure,slos You can optionally specify a timeout, which is the maximum amount of time to wait for the conditions to be satisfied: iter8 assert -c completed,nofailure,slos -t 5s iter8 assert [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_assert/#options","text":"-c, --condition strings completed | nofailure | slos; can specify multiple or separate conditions with commas; -h, --help help for assert --runDir string directory where experiment is run; contains experiment.yaml (default \".\") --timeout duration timeout duration (e.g., 5s)","title":"Options"},{"location":"user-guide/commands/iter8_assert/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_assert/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_assert/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_gen/","text":"iter8 gen \u00b6 Generate experiment.yaml file by combining an experiment chart with values Synopsis \u00b6 Generate an experiment.yaml file by combining the Iter8 experiment chart with values. iter8 gen --set \"tasks={http}\" --set http.url=https://httpbin.org/get This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. This command is intended for development and testing of local experiment charts. For production usage, the launch command is recommended. iter8 gen [flags] Options \u00b6 -c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") -h, --help help for gen --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple) Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 gen"},{"location":"user-guide/commands/iter8_gen/#iter8-gen","text":"Generate experiment.yaml file by combining an experiment chart with values","title":"iter8 gen"},{"location":"user-guide/commands/iter8_gen/#synopsis","text":"Generate an experiment.yaml file by combining the Iter8 experiment chart with values. iter8 gen --set \"tasks={http}\" --set http.url=https://httpbin.org/get This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. This command is intended for development and testing of local experiment charts. For production usage, the launch command is recommended. iter8 gen [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_gen/#options","text":"-c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") -h, --help help for gen --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple)","title":"Options"},{"location":"user-guide/commands/iter8_gen/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_gen/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_gen/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_hub/","text":"iter8 hub \u00b6 Download Iter8 experiment chart Synopsis \u00b6 Download the Iter8 experiment chart from a go-getter URL. iter8 hub This command is intended for development and testing of experiment charts. For production usage, the iter8 launch command is recommended. iter8 hub [flags] Options \u00b6 -h, --help help for hub --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\") Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 hub"},{"location":"user-guide/commands/iter8_hub/#iter8-hub","text":"Download Iter8 experiment chart","title":"iter8 hub"},{"location":"user-guide/commands/iter8_hub/#synopsis","text":"Download the Iter8 experiment chart from a go-getter URL. iter8 hub This command is intended for development and testing of experiment charts. For production usage, the iter8 launch command is recommended. iter8 hub [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_hub/#options","text":"-h, --help help for hub --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\")","title":"Options"},{"location":"user-guide/commands/iter8_hub/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_hub/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_hub/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k/","text":"iter8 k \u00b6 Work with Kubernetes experiments Synopsis \u00b6 Work with Kubernetes experiments Options \u00b6 -h, --help help for k --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -n, --namespace string namespace scope for this request Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer iter8 k assert - Assert if Kubernetes experiment result satisfies conditions iter8 k delete - Delete an experiment (group) in Kubernetes iter8 k launch - Launch an experiment inside a Kubernetes cluster iter8 k log - Fetch logs for a Kubernetes experiment iter8 k report - Generate report for Kubernetes experiment Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k"},{"location":"user-guide/commands/iter8_k/#iter8-k","text":"Work with Kubernetes experiments","title":"iter8 k"},{"location":"user-guide/commands/iter8_k/#synopsis","text":"Work with Kubernetes experiments","title":"Synopsis"},{"location":"user-guide/commands/iter8_k/#options","text":"-h, --help help for k --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -n, --namespace string namespace scope for this request","title":"Options"},{"location":"user-guide/commands/iter8_k/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k/#see-also","text":"iter8 - Kubernetes release optimizer iter8 k assert - Assert if Kubernetes experiment result satisfies conditions iter8 k delete - Delete an experiment (group) in Kubernetes iter8 k launch - Launch an experiment inside a Kubernetes cluster iter8 k log - Fetch logs for a Kubernetes experiment iter8 k report - Generate report for Kubernetes experiment","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k_assert/","text":"iter8 k assert \u00b6 Assert if Kubernetes experiment result satisfies conditions Synopsis \u00b6 Assert if the result of a Kubernetes experiment satisfies the specified conditions. If all conditions are satisfied, the command exits with code 0. Else, the command exits with code 1. Assertions are especially useful for automation inside CI/CD/GitOps pipelines. Supported conditions are 'completed', 'nofailure', 'slos', which indicate that the experiment has completed, none of the tasks have failed, and the SLOs are satisfied. iter8 k assert -c completed -c nofailure -c slos # same as iter8 k assert -c completed,nofailure,slos You can optionally specify a timeout, which is the maximum amount of time to wait for the conditions to be satisfied: iter8 k assert -c completed,nofailure,slos -t 5s iter8 k assert [flags] Options \u00b6 -c, --condition strings completed | nofailure | slos; can specify multiple or separate conditions with commas; -g, --group string name of the experiment group (default \"default\") -h, --help help for assert --timeout duration timeout duration (e.g., 5s) Options inherited from parent commands \u00b6 --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request SEE ALSO \u00b6 iter8 k - Work with Kubernetes experiments Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k assert"},{"location":"user-guide/commands/iter8_k_assert/#iter8-k-assert","text":"Assert if Kubernetes experiment result satisfies conditions","title":"iter8 k assert"},{"location":"user-guide/commands/iter8_k_assert/#synopsis","text":"Assert if the result of a Kubernetes experiment satisfies the specified conditions. If all conditions are satisfied, the command exits with code 0. Else, the command exits with code 1. Assertions are especially useful for automation inside CI/CD/GitOps pipelines. Supported conditions are 'completed', 'nofailure', 'slos', which indicate that the experiment has completed, none of the tasks have failed, and the SLOs are satisfied. iter8 k assert -c completed -c nofailure -c slos # same as iter8 k assert -c completed,nofailure,slos You can optionally specify a timeout, which is the maximum amount of time to wait for the conditions to be satisfied: iter8 k assert -c completed,nofailure,slos -t 5s iter8 k assert [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_k_assert/#options","text":"-c, --condition strings completed | nofailure | slos; can specify multiple or separate conditions with commas; -g, --group string name of the experiment group (default \"default\") -h, --help help for assert --timeout duration timeout duration (e.g., 5s)","title":"Options"},{"location":"user-guide/commands/iter8_k_assert/#options-inherited-from-parent-commands","text":"--kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k_assert/#see-also","text":"iter8 k - Work with Kubernetes experiments","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k_assert/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k_delete/","text":"iter8 k delete \u00b6 Delete an experiment (group) in Kubernetes Synopsis \u00b6 Delete an experiment (group) in Kubernetes. iter8 k delete iter8 k delete [flags] Options \u00b6 -g, --group string name of the experiment group (default \"default\") -h, --help help for delete Options inherited from parent commands \u00b6 --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request SEE ALSO \u00b6 iter8 k - Work with Kubernetes experiments Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k delete"},{"location":"user-guide/commands/iter8_k_delete/#iter8-k-delete","text":"Delete an experiment (group) in Kubernetes","title":"iter8 k delete"},{"location":"user-guide/commands/iter8_k_delete/#synopsis","text":"Delete an experiment (group) in Kubernetes. iter8 k delete iter8 k delete [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_k_delete/#options","text":"-g, --group string name of the experiment group (default \"default\") -h, --help help for delete","title":"Options"},{"location":"user-guide/commands/iter8_k_delete/#options-inherited-from-parent-commands","text":"--kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k_delete/#see-also","text":"iter8 k - Work with Kubernetes experiments","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k_delete/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k_launch/","text":"iter8 k launch \u00b6 Launch an experiment inside a Kubernetes cluster Synopsis \u00b6 Launch an experiment inside a Kubernetes cluster. iter8 k launch --set \"tasks={http}\" --set http.url=https://httpbin.org/get \\ --set runner=job Use the dry option to simulate a Kubernetes experiment. This creates the manifest.yaml file, but does not run the experiment, and does not deploy any experiment resource objects in the cluster. iter8 k launch \\ --set http.url=https://httpbin.org/get \\ --set runner=job \\ --dry The launch command creates the 'charts' subdirectory under the current working directory, downloads the Iter8 experiment chart, and places it under 'charts'. This behavior can be controlled using various launch flags. This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. iter8 k launch [flags] Options \u00b6 -c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") --dry simulate an experiment launch; outputs manifest.yaml file -g, --group string name of the experiment group (default \"default\") -h, --help help for launch --noDownload reuse local charts dir - do not download from remoteFolderURL; if local charts are present, this flag is required - set it to true or false; if local charts are absent, do not use this flag --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\") --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple) Options inherited from parent commands \u00b6 --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request SEE ALSO \u00b6 iter8 k - Work with Kubernetes experiments Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k launch"},{"location":"user-guide/commands/iter8_k_launch/#iter8-k-launch","text":"Launch an experiment inside a Kubernetes cluster","title":"iter8 k launch"},{"location":"user-guide/commands/iter8_k_launch/#synopsis","text":"Launch an experiment inside a Kubernetes cluster. iter8 k launch --set \"tasks={http}\" --set http.url=https://httpbin.org/get \\ --set runner=job Use the dry option to simulate a Kubernetes experiment. This creates the manifest.yaml file, but does not run the experiment, and does not deploy any experiment resource objects in the cluster. iter8 k launch \\ --set http.url=https://httpbin.org/get \\ --set runner=job \\ --dry The launch command creates the 'charts' subdirectory under the current working directory, downloads the Iter8 experiment chart, and places it under 'charts'. This behavior can be controlled using various launch flags. This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. iter8 k launch [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_k_launch/#options","text":"-c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") --dry simulate an experiment launch; outputs manifest.yaml file -g, --group string name of the experiment group (default \"default\") -h, --help help for launch --noDownload reuse local charts dir - do not download from remoteFolderURL; if local charts are present, this flag is required - set it to true or false; if local charts are absent, do not use this flag --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\") --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple)","title":"Options"},{"location":"user-guide/commands/iter8_k_launch/#options-inherited-from-parent-commands","text":"--kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k_launch/#see-also","text":"iter8 k - Work with Kubernetes experiments","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k_launch/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k_log/","text":"iter8 k log \u00b6 Fetch logs for a Kubernetes experiment Synopsis \u00b6 Fetch logs for a Kubernetes experiment. iter8 k log iter8 k log [flags] Options \u00b6 -g, --group string name of the experiment group (default \"default\") -h, --help help for log Options inherited from parent commands \u00b6 --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request SEE ALSO \u00b6 iter8 k - Work with Kubernetes experiments Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k log"},{"location":"user-guide/commands/iter8_k_log/#iter8-k-log","text":"Fetch logs for a Kubernetes experiment","title":"iter8 k log"},{"location":"user-guide/commands/iter8_k_log/#synopsis","text":"Fetch logs for a Kubernetes experiment. iter8 k log iter8 k log [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_k_log/#options","text":"-g, --group string name of the experiment group (default \"default\") -h, --help help for log","title":"Options"},{"location":"user-guide/commands/iter8_k_log/#options-inherited-from-parent-commands","text":"--kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k_log/#see-also","text":"iter8 k - Work with Kubernetes experiments","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k_log/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_k_report/","text":"iter8 k report \u00b6 Generate report for Kubernetes experiment Synopsis \u00b6 Generate a text or HTML report of a Kubernetes experiment. iter8 k report # same as iter8 k report -o text or iter8 k report -o html > report.html # view with browser iter8 k report [flags] Options \u00b6 -g, --group string name of the experiment group (default \"default\") -h, --help help for report -o, --outputFormat string text | html (default \"text\") Options inherited from parent commands \u00b6 --kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request SEE ALSO \u00b6 iter8 k - Work with Kubernetes experiments Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 k report"},{"location":"user-guide/commands/iter8_k_report/#iter8-k-report","text":"Generate report for Kubernetes experiment","title":"iter8 k report"},{"location":"user-guide/commands/iter8_k_report/#synopsis","text":"Generate a text or HTML report of a Kubernetes experiment. iter8 k report # same as iter8 k report -o text or iter8 k report -o html > report.html # view with browser iter8 k report [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_k_report/#options","text":"-g, --group string name of the experiment group (default \"default\") -h, --help help for report -o, --outputFormat string text | html (default \"text\")","title":"Options"},{"location":"user-guide/commands/iter8_k_report/#options-inherited-from-parent-commands","text":"--kube-apiserver string the address and the port for the Kubernetes API server --kube-as-group stringArray group to impersonate for the operation, this flag can be repeated to specify multiple groups. --kube-as-user string username to impersonate for the operation --kube-ca-file string the certificate authority file for the Kubernetes API server connection --kube-context string name of the kubeconfig context to use --kube-token string bearer token used for authentication --kubeconfig string path to the kubeconfig file -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") -n, --namespace string namespace scope for this request","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_k_report/#see-also","text":"iter8 k - Work with Kubernetes experiments","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_k_report/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_launch/","text":"iter8 launch \u00b6 Launch an experiment in the local environment Synopsis \u00b6 Launch an experiment in the local environment. iter8 launch --set \"tasks={http}\" \\ --set http.url=https://httpbin.org/get Use the dry option to simulate an experiment. This creates the experiment.yaml file but does not run the experiment. iter8 launch \\ --set http.url=https://httpbin.org/get \\ --dry The launch command creates the 'charts' subdirectory under the current working directory, downloads the Iter8 experiment chart, and places it under 'charts'. This behavior can be controlled using various launch flags. This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. iter8 launch [flags] Options \u00b6 -c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") --dry simulate an experiment launch; outputs experiment.yaml file -h, --help help for launch --noDownload reuse local charts dir - do not download from remoteFolderURL; if local charts are present, this flag is required - set it to true or false; if local charts are absent, do not use this flag --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\") --runDir string directory where experiment is run; contains experiment.yaml (default \".\") --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple) Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 launch"},{"location":"user-guide/commands/iter8_launch/#iter8-launch","text":"Launch an experiment in the local environment","title":"iter8 launch"},{"location":"user-guide/commands/iter8_launch/#synopsis","text":"Launch an experiment in the local environment. iter8 launch --set \"tasks={http}\" \\ --set http.url=https://httpbin.org/get Use the dry option to simulate an experiment. This creates the experiment.yaml file but does not run the experiment. iter8 launch \\ --set http.url=https://httpbin.org/get \\ --dry The launch command creates the 'charts' subdirectory under the current working directory, downloads the Iter8 experiment chart, and places it under 'charts'. This behavior can be controlled using various launch flags. This command supports setting values using the same mechanisms as in Helm. Please see https://helm.sh/docs/chart_template_guide/values_files/ for more detailed descriptions. In particular, this command supports the --set, --set-file, --set-string, and -f (--values) options all of which have the same behavior as in Helm. iter8 launch [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_launch/#options","text":"-c, --chartName string name of the experiment chart (default \"iter8\") --chartsParentDir string directory under which the charts folder is located (default \".\") --dry simulate an experiment launch; outputs experiment.yaml file -h, --help help for launch --noDownload reuse local charts dir - do not download from remoteFolderURL; if local charts are present, this flag is required - set it to true or false; if local charts are absent, do not use this flag --remoteFolderURL string URL of the remote folder containing the Iter8 experiment chart. Accepts any URL supported by https://github.com/hashicorp/go-getter (default \"github.com/iter8-tools/iter8.git?ref=v0.11.8//charts\") --runDir string directory where experiment is run; contains experiment.yaml (default \".\") --set stringArray set values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) --set-file stringArray set values from respective files specified via the command line (can specify multiple or separate values with commas: key1=path1,key2=path2) --set-string stringArray set STRING values on the command line (can specify multiple or separate values with commas: key1=val1,key2=val2) -f, --values strings specify values in a YAML file or a URL (can specify multiple)","title":"Options"},{"location":"user-guide/commands/iter8_launch/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_launch/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_launch/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_report/","text":"iter8 report \u00b6 Generate experiment report Synopsis \u00b6 Generate a text or HTML report of an experiment. iter8 report # same as iter8 report -o text or iter8 report -o html > report.html # view with browser iter8 report [flags] Options \u00b6 -h, --help help for report -o, --outputFormat string text | html (default \"text\") --runDir string directory where experiment is run; contains experiment.yaml (default \".\") Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 report"},{"location":"user-guide/commands/iter8_report/#iter8-report","text":"Generate experiment report","title":"iter8 report"},{"location":"user-guide/commands/iter8_report/#synopsis","text":"Generate a text or HTML report of an experiment. iter8 report # same as iter8 report -o text or iter8 report -o html > report.html # view with browser iter8 report [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_report/#options","text":"-h, --help help for report -o, --outputFormat string text | html (default \"text\") --runDir string directory where experiment is run; contains experiment.yaml (default \".\")","title":"Options"},{"location":"user-guide/commands/iter8_report/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_report/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_report/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_run/","text":"iter8 run \u00b6 Run an experiment Synopsis \u00b6 Run an experiment specified in experiment.yaml. This command modifies the experiment.yaml file as part of the run. iter8 run This command is intended for development and testing of experiment charts and tasks. For production usage, the iter8 launch command is recommended. iter8 run [flags] Options \u00b6 -h, --help help for run --reuseResult reuse experiment result; useful for experiments with multiple loops such as Kubernetes experiments with a cronjob runner --runDir string directory where experiment is run; contains experiment.yaml (default \".\") Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 run"},{"location":"user-guide/commands/iter8_run/#iter8-run","text":"Run an experiment","title":"iter8 run"},{"location":"user-guide/commands/iter8_run/#synopsis","text":"Run an experiment specified in experiment.yaml. This command modifies the experiment.yaml file as part of the run. iter8 run This command is intended for development and testing of experiment charts and tasks. For production usage, the iter8 launch command is recommended. iter8 run [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_run/#options","text":"-h, --help help for run --reuseResult reuse experiment result; useful for experiments with multiple loops such as Kubernetes experiments with a cronjob runner --runDir string directory where experiment is run; contains experiment.yaml (default \".\")","title":"Options"},{"location":"user-guide/commands/iter8_run/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_run/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_run/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/commands/iter8_version/","text":"iter8 version \u00b6 Print Iter8 CLI version Synopsis \u00b6 Print the version of Iter8 CLI. iter8 version The output may look as follows: $ version.BuildInfo{Version:\"v0.11.0\", GitCommit:\"fe51cd1e31e6a202cba7aliv9552a6d418ded79a\", GoVersion:\"go1.17.6\"} In the sample output shown above: Version is the semantic version of the Iter8 CLI. GitCommit is the SHA hash for the commit that this version was built from. GoVersion is the version of Go that was used to compile Iter8 CLI. iter8 version [flags] Options \u00b6 -h, --help help for version --short print abbreviated version info Options inherited from parent commands \u00b6 -l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\") SEE ALSO \u00b6 iter8 - Kubernetes release optimizer Auto generated by spf13/cobra on 12-Jul-2022 \u00b6","title":"iter8 version"},{"location":"user-guide/commands/iter8_version/#iter8-version","text":"Print Iter8 CLI version","title":"iter8 version"},{"location":"user-guide/commands/iter8_version/#synopsis","text":"Print the version of Iter8 CLI. iter8 version The output may look as follows: $ version.BuildInfo{Version:\"v0.11.0\", GitCommit:\"fe51cd1e31e6a202cba7aliv9552a6d418ded79a\", GoVersion:\"go1.17.6\"} In the sample output shown above: Version is the semantic version of the Iter8 CLI. GitCommit is the SHA hash for the commit that this version was built from. GoVersion is the version of Go that was used to compile Iter8 CLI. iter8 version [flags]","title":"Synopsis"},{"location":"user-guide/commands/iter8_version/#options","text":"-h, --help help for version --short print abbreviated version info","title":"Options"},{"location":"user-guide/commands/iter8_version/#options-inherited-from-parent-commands","text":"-l, --loglevel string trace, debug, info, warning, error, fatal, panic (default \"info\")","title":"Options inherited from parent commands"},{"location":"user-guide/commands/iter8_version/#see-also","text":"iter8 - Kubernetes release optimizer","title":"SEE ALSO"},{"location":"user-guide/commands/iter8_version/#auto-generated-by-spf13cobra-on-12-jul-2022","text":"","title":"Auto generated by spf13/cobra on 12-Jul-2022"},{"location":"user-guide/tasks/assess/","text":"assess \u00b6 Assess if service-level objectives (SLOs) are satisfied by app versions. Usage example \u00b6 In this experiment, the assess task validates if the http/latency-mean metric has a value that does not exceed 50, and the http/error-count metric has a value that does not exceed 0. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url=https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean=50 \\ --set assess.SLOs.upper.http/error-count=0 Parameters \u00b6 Name Type Description SLOs struct Service-level objectives that will be validated by this task. This struct contains two fields upper and lower . upper \u00b6 Name Type Description upper map[string]float Map keys are fully-qualified metric names and map values are upper limits of those metrics. lower \u00b6 Name Type Description lower map[string]float Map keys are fully-qualified metric names and map values are lower limits of those metrics.","title":"assess"},{"location":"user-guide/tasks/assess/#assess","text":"Assess if service-level objectives (SLOs) are satisfied by app versions.","title":"assess"},{"location":"user-guide/tasks/assess/#usage-example","text":"In this experiment, the assess task validates if the http/latency-mean metric has a value that does not exceed 50, and the http/error-count metric has a value that does not exceed 0. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url=https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean=50 \\ --set assess.SLOs.upper.http/error-count=0","title":"Usage example"},{"location":"user-guide/tasks/assess/#parameters","text":"Name Type Description SLOs struct Service-level objectives that will be validated by this task. This struct contains two fields upper and lower .","title":"Parameters"},{"location":"user-guide/tasks/assess/#upper","text":"Name Type Description upper map[string]float Map keys are fully-qualified metric names and map values are upper limits of those metrics.","title":"upper"},{"location":"user-guide/tasks/assess/#lower","text":"Name Type Description lower map[string]float Map keys are fully-qualified metric names and map values are lower limits of those metrics.","title":"lower"},{"location":"user-guide/tasks/custommetrics/","text":"custommetrics \u00b6 Fetch metrics from databases (like Prometheus) and other REST APIs. Usage Example \u00b6 In this example, the custommetrics task fetches metrics from the Prometheus database that is created by Istio's Prometheus add-on . iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkload = httpbin \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" Parameters \u00b6 Name Type Description templates map[string]string A map where each key is the name of a provider , and the corresponding value is a URL containing the provider template . values map[string]interface{} A map that contains the values for variables in provider templates . When there are two or more app versions, this map contains values that are common to all versions. versionValues []map[string]interface{} An array that contains version-specific values for variables in provider templates . While fetching metrics for version i , the task merges values with versionValues[i] (latter takes precedence), and the merged map contains the values for variables in provider templates. How it works \u00b6 The logic of this task is illustrated by the following flowchart. graph TD A([Start]) --> B([Get provider template]); B --> C([Compute variable values]); C --> D([Create provider spec by combining template with values]); D --> E([Query database]); E --> F([Process response]); F --> G([Update metric value in experiment]); G --> H{Done with all metrics?}; H ---->|No| E; H ---->|Yes| I{Done with all versions?}; I ---->|No| C; I ---->|Yes| J([End]); We describe the concepts or provider spec and provider template next. Provider spec \u00b6 Iter8 needs the information following in order to fetch metrics from a database. The HTTP URL where the database can be queried. The HTTP headers and method (GET/POST) to be used while querying the database. For each metric to be fetched from the database: The specific HTTP query to be used, in particular, the HTTP query parameters and body (if any). The logic for parsing the query response and retrieving the metric value. The above information is encapsulated by ProviderSpec , a data structure which Iter8 associates with each provider, and Metric , a data structure which Iter8 associates with each metric provided by a provider. Golang type definitions for ProviderSpec and Metric 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 type ProviderSpec struct { // URL is the database endpoint URL string `json:\"url\" yaml:\"url\"` // Method is the HTTP method that needs to be used Method string `json:\"method\" yaml:\"method\"` // Headers is the set of HTTP headers that need to be sent Headers map [ string ] string `json:\"headers\" yaml:\"headers\"` // Metrics is the set of metrics that can be obtained Metrics [] Metric `json:\"metrics\" yaml:\"metrics\"` } type Metric struct { // Name is the name of the metric Name string `json:\"name\" yaml:\"name\"` // Description is the description of the metric Description * string `json:\"description,omitempty\" yaml:\"description,omitempty\"` // Type is the type of the metric, either gauge or counter Type string `json:\"type\" yaml:\"type\"` // Units is the unit of the metric, which can be omitted for unitless metrics Units * string `json:\"units,omitempty\" yaml:\"units,omitempty\"` // Params is the set of HTTP parameters that need to be sent Params * [] HTTPParam `json:\"params,omitempty\" yaml:\"params,omitempty\"` // Body is the HTTP request body that needs to be sent Body * string `json:\"body,omitempty\" yaml:\"body,omitempty\"` // JqExpression is the jq expression that can extract the value from the HTTP // response JqExpression string `json:\"jqExpression\" yaml:\"jqExpression\"` } type HTTPParam struct { // Name is the name of the HTTP parameter Name string `json:\"name\" yaml:\"name\"` // Value is the value of the HTTP parameter Value string `json:\"value\" yaml:\"value\"` } The ProviderSpec and Metric data structures together supply Iter8 with all the information needed to query databases, process the response to extract metric values, store the metric values in experiments, and display them in experiment reports with auxiliary information (such as description and units). Metric types are defined here . Provider template \u00b6 Rather than supplying provider specs directly, Iter8 enables users to supply one or more Golang templates for provider specs. Iter8 combines the provider templates with values , in order to generate provider specs in YAML format, and uses them to query for the metrics. istio-prom provider template in the usage example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 # This file provides templated metric specifications that enable # Iter8 to retrieve metrics from Istio's Prometheus add-on. # # For a list of metrics supported out-of-the-box by the Istio Prom add-on, # please see https://istio.io/latest/docs/reference/config/metrics/ # # Iter8 substitutes the placeholders in this file with values, # and uses the resulting metric specs to query Prometheus. # The placeholders are as follows. # # reporter string optional # destinationWorkload string required # destinationWorkloadNamespace string required # elapsedTimeSeconds int implicit # startingTime string optional # latencyPercentiles []int optional # # For descriptions of reporter, destinationWorkload, and destinationWorkloadNamespace, # please see https://istio.io/latest/docs/reference/config/metrics/ # # elapsedTimeSeconds: this should not be specified directly by the user. # It is implicitly computed by Iter8 according to the following formula # elapsedTimeSeconds := (time.Now() - startingTime).Seconds() # # startingTime: By default, this is the time at which the Iter8 experiment started. # The user can explicitly specify the startingTime for each app version # (for example, the user can set the startingTime to the creation time of the app version) # # latencyPercentiles: Each item in this slice will create a new metric spec. # For example, if this is set to [50,75,90,95], # then, latency-p50, latency-p75, latency-p90, latency-p95 metric specs are created. {{ - define \"istio-prom-reporter\" }} {{ - if .reporter }} reporter=\"{{ .reporter }}\", {{- end }} {{- end }} {{- define \"istio-prom-dest\"}} {{ template \"istio-prom-reporter\" . }} destination_workload=\"{{ .destinationWorkload }}\", destination_workload_namespace=\"{{ .destinationWorkloadNamespace }}\" {{- end }} # url is the HTTP endpoint where the Prometheus service installed by Istio's Prom add-on # can be queried for metrics url : {{ default .istioPromURL \"http : //prometheus.istio-system : 9090/api/v1/query\" }} provider : istio-prom method : GET metrics : - name : request-count type : counter description : | Number of requests params : - name : query value : | sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0) jqExpression : .data.result[0].value[1] | tonumber - name : error-count type : counter description : | Number of unsuccessful requests params : - name : query value : | sum(last_over_time(istio_requests_total{ response_code=~'5..', {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0) jqExpression : .data.result[0].value[1] | tonumber - name : error-rate type : gauge description : | Fraction of unsuccessful requests params : - name : query value : | (sum(last_over_time(istio_requests_total{ response_code=~'5..', {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0))/(sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0)) jqExpression : .data.result.[0].value.[1] - name : latency-mean type : gauge description : | Mean latency params : - name : query value : | (sum(last_over_time(istio_request_duration_milliseconds_sum{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0))/(sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0)) jqExpression : .data.result[0].value[1] | tonumber {{ - range $i , $p : = .latencyPercentiles }} - name : latency-p{{ $p }} type : gauge description : | {{ $p }} percentile latency params : - name : query value : | histogram_quantile(0.{{ $p }}, sum(rate(istio_request_duration_milliseconds_bucket{ {{ template \"istio-prom-dest\" $ }} }[{{ .elapsedTimeSeconds }}s])) by (le)) jqExpression : .data.result[0].value[1] | tonumber {{ - end }} In order to create provider templates and use them in experiments, it is necessary to have a clear understanding of how variable values are computed, and how the response from the database is processed by Iter8. We describe these steps next. Computing variable values \u00b6 Variable values are configured explicitly by the user during experiment launch. The sole exception to this rule is the elapsedTimeSeconds variable which is computed by Iter8. Please see the tabs below to learn more about how to configure values and how Iter8 computes elapsedTimeSeconds . Configure values for one version Configure values for multiple versions How Iter8 computes elapsedTimeSeconds When the experiment involves a single version of the app, template variable values are supplied directly as part of the custommetrics.values map. See usage example for an illustration. When the experiment involves two or more versions of the app, values that are shared by all versions are supplied as part of the custommetrics.values map, and values that are specific to versions are supplied as part of the custommetrics.versionValues list. The length of this list is the number of versions, and custommetrics.versionValues[i] is the map that holds values specific to version i . Iter8 merges custommetrics.values with custommetrics.versionValues[i] (latter takes precedence), and uses the resulting map for version i when substituting template variables. Configuring values for two versions is illustrated in the following usage example. iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set custommetrics.values.reporter = destination \\ --set custommetrics.versionValues [ 0 ] .destinationWorkload = httpbin-v1 \\ --set custommetrics.versionValues [ 1 ] .destinationWorkload = httpbin-v2 \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" A metric query often involves specifying the time window over which the metric need to be computed. In provider templates , a special template variable named elapsedTimeSeconds holds the length of this time window. Its use within a template is illustrated in the following snippets. query query template sum ( last_over_time ( istio_requests_total { destination_workload = \"httpbin\" , destination_workload_namespace = \"default\" }[ 3600 s ])) The metric is computed over the recent one-hour time window (that ends at the current time). sum ( last_over_time ( istio_requests_total { destination_workload = \"httpbin\" , destination_workload_namespace = \"default\" }[{{ . elapsedTimeSeconds }} s ])) The metric is computed over a recent time window (that ends at the current time). The length of this window is determined by the value of the template variable elapsedTimeSeconds . Iter8 computes the value of the elapsedTimeSeconds variable dynamically in this task. This is the desirable behavior in multi-loop experiments (see usage example ), where metrics need to be fetched periodically, and the time window over which metrics are computed stretches farther back with each loop. The following sequence diagram illustrates how elapsedTimeSeconds changes over loops. sequenceDiagram startingTime-)loop1: elapsedTimeSeconds=60; startingTime-)loop2: elapsedTimeSeconds=120; startingTime-)loop3: elapsedTimeSeconds=180; Iter8 computes elapsedTimeSeconds based on another variable named startingTime . The default value of startingTime is the time at which the experiment is launched. The user can override the default by explicitly configuring startingTime during experiment launch, in the RFC 3339 format (for example, 2020-02-01T09:44:40Z or 2020-02-01T09:44:40.954641934Z ). Iter8 sets elapsedTimeSeconds as the difference (in seconds) between the current time and startingTime . This logic is illustrated in the following flowchart. graph TD A([Start]) --> B{startingTime parameter supplied?}; B ---->|Yes| C([elapsedTimeSeconds = currentTime - startingTime]); B ---->|No| D([startingTime = time when experiment was launched]); D --> C; C --> E([End]); Note that the above design enables the user to supply different startingTime values for different app versions (for instance, based on the creation timestamps of the versions). Single startingTime value Two versions with different startingTime values --set custommetrics.values.startingTime = \"2020-02-01T09:44:40Z\" --set custommetrics.versionValues [ 0 ] .startingTime = \"2020-02-01T09:44:40Z\" \\ --set custommetrics.versionValues [ 1 ] .startingTime = \"2020-02-05T14:22:15Z\" Processing response \u00b6 The metrics provider is expected to respond to Iter8's HTTP request for a metric with a JSON object. The format of this JSON object is provider-specific. Iter8 uses jq to extract the metric value from the JSON response of the provider. The jqExpression used by Iter8 is supplied as part of the metric definition. When the jqExpression is applied to the JSON response, it is expected to yield a number. Prometheus response example Prometheus jqExpression example The format of the Prometheus JSON response is defined here . A sample Prometheus response is as follows. 1 2 3 4 5 6 7 8 9 10 11 { \"status\" : \"success\" , \"data\" : { \"resultType\" : \"vector\" , \"result\" : [ { \"value\" : [ 1556823494.744 , \"21.7639\" ] } ] } } Consider the jqExpression defined in the sample Prometheus metric . Let us apply it to the sample JSON response from Prometheus . echo '{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"value\": [1556823494.744, \"21.7639\"] } ] } }' | jq \".data.result[0].value[1] | tonumber\" Executing the above command results yields 21.7639 , a number, as required by Iter8. Note: The shell command above is for illustration only. Iter8 uses Python bindings for jq to evaluate the jqExpression . Defining and using providers \u00b6 Understand how the custommetrics task works; this is described in this section . Create your provider template and serve it from a URL. A sample provider template is in this section . Configure the custommetrics task with one or more provider templates. An example of custommetrics configuration is in this section . The metrics fetched by this task can be used to assess app versions in Iter8 experiments. An example that illustrates the use of both custommetrics and assess tasks together is in this section .","title":"custommetrics"},{"location":"user-guide/tasks/custommetrics/#custommetrics","text":"Fetch metrics from databases (like Prometheus) and other REST APIs.","title":"custommetrics"},{"location":"user-guide/tasks/custommetrics/#usage-example","text":"In this example, the custommetrics task fetches metrics from the Prometheus database that is created by Istio's Prometheus add-on . iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkload = httpbin \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\"","title":"Usage Example"},{"location":"user-guide/tasks/custommetrics/#parameters","text":"Name Type Description templates map[string]string A map where each key is the name of a provider , and the corresponding value is a URL containing the provider template . values map[string]interface{} A map that contains the values for variables in provider templates . When there are two or more app versions, this map contains values that are common to all versions. versionValues []map[string]interface{} An array that contains version-specific values for variables in provider templates . While fetching metrics for version i , the task merges values with versionValues[i] (latter takes precedence), and the merged map contains the values for variables in provider templates.","title":"Parameters"},{"location":"user-guide/tasks/custommetrics/#how-it-works","text":"The logic of this task is illustrated by the following flowchart. graph TD A([Start]) --> B([Get provider template]); B --> C([Compute variable values]); C --> D([Create provider spec by combining template with values]); D --> E([Query database]); E --> F([Process response]); F --> G([Update metric value in experiment]); G --> H{Done with all metrics?}; H ---->|No| E; H ---->|Yes| I{Done with all versions?}; I ---->|No| C; I ---->|Yes| J([End]); We describe the concepts or provider spec and provider template next.","title":"How it works"},{"location":"user-guide/tasks/custommetrics/#provider-spec","text":"Iter8 needs the information following in order to fetch metrics from a database. The HTTP URL where the database can be queried. The HTTP headers and method (GET/POST) to be used while querying the database. For each metric to be fetched from the database: The specific HTTP query to be used, in particular, the HTTP query parameters and body (if any). The logic for parsing the query response and retrieving the metric value. The above information is encapsulated by ProviderSpec , a data structure which Iter8 associates with each provider, and Metric , a data structure which Iter8 associates with each metric provided by a provider. Golang type definitions for ProviderSpec and Metric 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 type ProviderSpec struct { // URL is the database endpoint URL string `json:\"url\" yaml:\"url\"` // Method is the HTTP method that needs to be used Method string `json:\"method\" yaml:\"method\"` // Headers is the set of HTTP headers that need to be sent Headers map [ string ] string `json:\"headers\" yaml:\"headers\"` // Metrics is the set of metrics that can be obtained Metrics [] Metric `json:\"metrics\" yaml:\"metrics\"` } type Metric struct { // Name is the name of the metric Name string `json:\"name\" yaml:\"name\"` // Description is the description of the metric Description * string `json:\"description,omitempty\" yaml:\"description,omitempty\"` // Type is the type of the metric, either gauge or counter Type string `json:\"type\" yaml:\"type\"` // Units is the unit of the metric, which can be omitted for unitless metrics Units * string `json:\"units,omitempty\" yaml:\"units,omitempty\"` // Params is the set of HTTP parameters that need to be sent Params * [] HTTPParam `json:\"params,omitempty\" yaml:\"params,omitempty\"` // Body is the HTTP request body that needs to be sent Body * string `json:\"body,omitempty\" yaml:\"body,omitempty\"` // JqExpression is the jq expression that can extract the value from the HTTP // response JqExpression string `json:\"jqExpression\" yaml:\"jqExpression\"` } type HTTPParam struct { // Name is the name of the HTTP parameter Name string `json:\"name\" yaml:\"name\"` // Value is the value of the HTTP parameter Value string `json:\"value\" yaml:\"value\"` } The ProviderSpec and Metric data structures together supply Iter8 with all the information needed to query databases, process the response to extract metric values, store the metric values in experiments, and display them in experiment reports with auxiliary information (such as description and units). Metric types are defined here .","title":"Provider spec"},{"location":"user-guide/tasks/custommetrics/#provider-template","text":"Rather than supplying provider specs directly, Iter8 enables users to supply one or more Golang templates for provider specs. Iter8 combines the provider templates with values , in order to generate provider specs in YAML format, and uses them to query for the metrics. istio-prom provider template in the usage example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 # This file provides templated metric specifications that enable # Iter8 to retrieve metrics from Istio's Prometheus add-on. # # For a list of metrics supported out-of-the-box by the Istio Prom add-on, # please see https://istio.io/latest/docs/reference/config/metrics/ # # Iter8 substitutes the placeholders in this file with values, # and uses the resulting metric specs to query Prometheus. # The placeholders are as follows. # # reporter string optional # destinationWorkload string required # destinationWorkloadNamespace string required # elapsedTimeSeconds int implicit # startingTime string optional # latencyPercentiles []int optional # # For descriptions of reporter, destinationWorkload, and destinationWorkloadNamespace, # please see https://istio.io/latest/docs/reference/config/metrics/ # # elapsedTimeSeconds: this should not be specified directly by the user. # It is implicitly computed by Iter8 according to the following formula # elapsedTimeSeconds := (time.Now() - startingTime).Seconds() # # startingTime: By default, this is the time at which the Iter8 experiment started. # The user can explicitly specify the startingTime for each app version # (for example, the user can set the startingTime to the creation time of the app version) # # latencyPercentiles: Each item in this slice will create a new metric spec. # For example, if this is set to [50,75,90,95], # then, latency-p50, latency-p75, latency-p90, latency-p95 metric specs are created. {{ - define \"istio-prom-reporter\" }} {{ - if .reporter }} reporter=\"{{ .reporter }}\", {{- end }} {{- end }} {{- define \"istio-prom-dest\"}} {{ template \"istio-prom-reporter\" . }} destination_workload=\"{{ .destinationWorkload }}\", destination_workload_namespace=\"{{ .destinationWorkloadNamespace }}\" {{- end }} # url is the HTTP endpoint where the Prometheus service installed by Istio's Prom add-on # can be queried for metrics url : {{ default .istioPromURL \"http : //prometheus.istio-system : 9090/api/v1/query\" }} provider : istio-prom method : GET metrics : - name : request-count type : counter description : | Number of requests params : - name : query value : | sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0) jqExpression : .data.result[0].value[1] | tonumber - name : error-count type : counter description : | Number of unsuccessful requests params : - name : query value : | sum(last_over_time(istio_requests_total{ response_code=~'5..', {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0) jqExpression : .data.result[0].value[1] | tonumber - name : error-rate type : gauge description : | Fraction of unsuccessful requests params : - name : query value : | (sum(last_over_time(istio_requests_total{ response_code=~'5..', {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0))/(sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0)) jqExpression : .data.result.[0].value.[1] - name : latency-mean type : gauge description : | Mean latency params : - name : query value : | (sum(last_over_time(istio_request_duration_milliseconds_sum{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0))/(sum(last_over_time(istio_requests_total{ {{ template \"istio-prom-dest\" . }} }[{{ .elapsedTimeSeconds }}s])) or on() vector(0)) jqExpression : .data.result[0].value[1] | tonumber {{ - range $i , $p : = .latencyPercentiles }} - name : latency-p{{ $p }} type : gauge description : | {{ $p }} percentile latency params : - name : query value : | histogram_quantile(0.{{ $p }}, sum(rate(istio_request_duration_milliseconds_bucket{ {{ template \"istio-prom-dest\" $ }} }[{{ .elapsedTimeSeconds }}s])) by (le)) jqExpression : .data.result[0].value[1] | tonumber {{ - end }} In order to create provider templates and use them in experiments, it is necessary to have a clear understanding of how variable values are computed, and how the response from the database is processed by Iter8. We describe these steps next.","title":"Provider template"},{"location":"user-guide/tasks/custommetrics/#computing-variable-values","text":"Variable values are configured explicitly by the user during experiment launch. The sole exception to this rule is the elapsedTimeSeconds variable which is computed by Iter8. Please see the tabs below to learn more about how to configure values and how Iter8 computes elapsedTimeSeconds . Configure values for one version Configure values for multiple versions How Iter8 computes elapsedTimeSeconds When the experiment involves a single version of the app, template variable values are supplied directly as part of the custommetrics.values map. See usage example for an illustration. When the experiment involves two or more versions of the app, values that are shared by all versions are supplied as part of the custommetrics.values map, and values that are specific to versions are supplied as part of the custommetrics.versionValues list. The length of this list is the number of versions, and custommetrics.versionValues[i] is the map that holds values specific to version i . Iter8 merges custommetrics.values with custommetrics.versionValues[i] (latter takes precedence), and uses the resulting map for version i when substituting template variables. Configuring values for two versions is illustrated in the following usage example. iter8 k launch \\ --set \"tasks={custommetrics,assess}\" \\ --set custommetrics.templates.istio-prom = \"https://raw.githubusercontent.com/iter8-tools/iter8/master/custommetrics/istio-prom.tpl\" \\ --set custommetrics.values.destinationWorkloadNamespace = default \\ --set custommetrics.values.reporter = destination \\ --set custommetrics.versionValues [ 0 ] .destinationWorkload = httpbin-v1 \\ --set custommetrics.versionValues [ 1 ] .destinationWorkload = httpbin-v2 \\ --set assess.SLOs.upper.istio-prom/error-rate = 0 \\ --set assess.SLOs.upper.istio-prom/latency-mean = 100 \\ --set runner = cronjob \\ --set cronjobSchedule = \"*/1 * * * *\" A metric query often involves specifying the time window over which the metric need to be computed. In provider templates , a special template variable named elapsedTimeSeconds holds the length of this time window. Its use within a template is illustrated in the following snippets. query query template sum ( last_over_time ( istio_requests_total { destination_workload = \"httpbin\" , destination_workload_namespace = \"default\" }[ 3600 s ])) The metric is computed over the recent one-hour time window (that ends at the current time). sum ( last_over_time ( istio_requests_total { destination_workload = \"httpbin\" , destination_workload_namespace = \"default\" }[{{ . elapsedTimeSeconds }} s ])) The metric is computed over a recent time window (that ends at the current time). The length of this window is determined by the value of the template variable elapsedTimeSeconds . Iter8 computes the value of the elapsedTimeSeconds variable dynamically in this task. This is the desirable behavior in multi-loop experiments (see usage example ), where metrics need to be fetched periodically, and the time window over which metrics are computed stretches farther back with each loop. The following sequence diagram illustrates how elapsedTimeSeconds changes over loops. sequenceDiagram startingTime-)loop1: elapsedTimeSeconds=60; startingTime-)loop2: elapsedTimeSeconds=120; startingTime-)loop3: elapsedTimeSeconds=180; Iter8 computes elapsedTimeSeconds based on another variable named startingTime . The default value of startingTime is the time at which the experiment is launched. The user can override the default by explicitly configuring startingTime during experiment launch, in the RFC 3339 format (for example, 2020-02-01T09:44:40Z or 2020-02-01T09:44:40.954641934Z ). Iter8 sets elapsedTimeSeconds as the difference (in seconds) between the current time and startingTime . This logic is illustrated in the following flowchart. graph TD A([Start]) --> B{startingTime parameter supplied?}; B ---->|Yes| C([elapsedTimeSeconds = currentTime - startingTime]); B ---->|No| D([startingTime = time when experiment was launched]); D --> C; C --> E([End]); Note that the above design enables the user to supply different startingTime values for different app versions (for instance, based on the creation timestamps of the versions). Single startingTime value Two versions with different startingTime values --set custommetrics.values.startingTime = \"2020-02-01T09:44:40Z\" --set custommetrics.versionValues [ 0 ] .startingTime = \"2020-02-01T09:44:40Z\" \\ --set custommetrics.versionValues [ 1 ] .startingTime = \"2020-02-05T14:22:15Z\"","title":"Computing variable values"},{"location":"user-guide/tasks/custommetrics/#processing-response","text":"The metrics provider is expected to respond to Iter8's HTTP request for a metric with a JSON object. The format of this JSON object is provider-specific. Iter8 uses jq to extract the metric value from the JSON response of the provider. The jqExpression used by Iter8 is supplied as part of the metric definition. When the jqExpression is applied to the JSON response, it is expected to yield a number. Prometheus response example Prometheus jqExpression example The format of the Prometheus JSON response is defined here . A sample Prometheus response is as follows. 1 2 3 4 5 6 7 8 9 10 11 { \"status\" : \"success\" , \"data\" : { \"resultType\" : \"vector\" , \"result\" : [ { \"value\" : [ 1556823494.744 , \"21.7639\" ] } ] } } Consider the jqExpression defined in the sample Prometheus metric . Let us apply it to the sample JSON response from Prometheus . echo '{ \"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [ { \"value\": [1556823494.744, \"21.7639\"] } ] } }' | jq \".data.result[0].value[1] | tonumber\" Executing the above command results yields 21.7639 , a number, as required by Iter8. Note: The shell command above is for illustration only. Iter8 uses Python bindings for jq to evaluate the jqExpression .","title":"Processing response"},{"location":"user-guide/tasks/custommetrics/#defining-and-using-providers","text":"Understand how the custommetrics task works; this is described in this section . Create your provider template and serve it from a URL. A sample provider template is in this section . Configure the custommetrics task with one or more provider templates. An example of custommetrics configuration is in this section . The metrics fetched by this task can be used to assess app versions in Iter8 experiments. An example that illustrates the use of both custommetrics and assess tasks together is in this section .","title":"Defining and using providers"},{"location":"user-guide/tasks/grpc/","text":"grpc \u00b6 Generate requests for a gRPC service and and collect latency and error-related metrics . Usage example \u00b6 In this experiment, the grpc task generates call requests for a gRPC service hosted at hello.default:50051 , defined in the protobuf file located at grpc.protoURL , with a gRPC method named helloworld.Greeter.SayHello . Metrics collected by this task are used by the assess task to validate SLOs. iter8 k launch \\ --set \"tasks={grpc,assess}\" \\ --set grpc.host=\"hello.default:50051\" \\ --set grpc.call=\"helloworld.Greeter.SayHello\" \\ --set grpc.protoURL=\"https://raw.githubusercontent.com/grpc/grpc-go/master/examples/helloworld/helloworld/helloworld.proto\" \\ --set assess.SLOs.upper.grpc/error-rate=0 \\ --set assess.SLOs.upper.grpc/latency/p'97\\.5'=800 \\ --set runner=job Parameters \u00b6 Any field in the Config struct of the ghz runner package can be used as a parameter in this task. The JSON tags of the struct fields directly correspond to the names of the parameters of this task. In the usage example , the parameters host and call correspond to the Call and Host fields respectively in the Config struct. In addition, the following fields are defined by this task. Name Type Description protoURL string (URL) URL where the protobuf file that defines the gRPC service is located. dataURL string (URL) URL where JSON data to be used in call requests is located. binaryDataURL string (URL) URL where binary data to be used in call requests is located. metadataURL string (URL) URL where the JSON metadata data to be used in call requests is located. Metrics \u00b6 This task creates a built-in provider named grpc . The following metrics are collected by this task: grpc/request-count : total number of requests sent grpc/error-count : number of error responses grpc/error-rate : fraction of error responses The following latency metrics are also supported by this task. grpc/latency/mean : mean latency grpc/latency/stddev : standard deviation of latency grpc/latency/min : min latency grpc/latency/max : max latency grpc/latency/pX : X th percentile latency, for any X in the range 0.0 to 100.0 All latency metrics have msec units.","title":"grpc"},{"location":"user-guide/tasks/grpc/#grpc","text":"Generate requests for a gRPC service and and collect latency and error-related metrics .","title":"grpc"},{"location":"user-guide/tasks/grpc/#usage-example","text":"In this experiment, the grpc task generates call requests for a gRPC service hosted at hello.default:50051 , defined in the protobuf file located at grpc.protoURL , with a gRPC method named helloworld.Greeter.SayHello . Metrics collected by this task are used by the assess task to validate SLOs. iter8 k launch \\ --set \"tasks={grpc,assess}\" \\ --set grpc.host=\"hello.default:50051\" \\ --set grpc.call=\"helloworld.Greeter.SayHello\" \\ --set grpc.protoURL=\"https://raw.githubusercontent.com/grpc/grpc-go/master/examples/helloworld/helloworld/helloworld.proto\" \\ --set assess.SLOs.upper.grpc/error-rate=0 \\ --set assess.SLOs.upper.grpc/latency/p'97\\.5'=800 \\ --set runner=job","title":"Usage example"},{"location":"user-guide/tasks/grpc/#parameters","text":"Any field in the Config struct of the ghz runner package can be used as a parameter in this task. The JSON tags of the struct fields directly correspond to the names of the parameters of this task. In the usage example , the parameters host and call correspond to the Call and Host fields respectively in the Config struct. In addition, the following fields are defined by this task. Name Type Description protoURL string (URL) URL where the protobuf file that defines the gRPC service is located. dataURL string (URL) URL where JSON data to be used in call requests is located. binaryDataURL string (URL) URL where binary data to be used in call requests is located. metadataURL string (URL) URL where the JSON metadata data to be used in call requests is located.","title":"Parameters"},{"location":"user-guide/tasks/grpc/#metrics","text":"This task creates a built-in provider named grpc . The following metrics are collected by this task: grpc/request-count : total number of requests sent grpc/error-count : number of error responses grpc/error-rate : fraction of error responses The following latency metrics are also supported by this task. grpc/latency/mean : mean latency grpc/latency/stddev : standard deviation of latency grpc/latency/min : min latency grpc/latency/max : max latency grpc/latency/pX : X th percentile latency, for any X in the range 0.0 to 100.0 All latency metrics have msec units.","title":"Metrics"},{"location":"user-guide/tasks/http/","text":"http \u00b6 Generate requests for an HTTP service and and collect latency and error-related metrics . Usage example \u00b6 In this experiment, the http task generates requests for https://httpbin.org/get , and collects latency and error-related metrics. The metrics are used by the assess task to validate SLOs. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url=https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean=50 \\ --set assess.SLOs.upper.http/error-count=0 Parameters \u00b6 Name Type Description url string (URL) HTTP URL where requests are sent. headers map[string]string HTTP headers to use in the requests. numRequests int Number of requests to be sent to the app. Default value is 100. duration string Duration of this task. Specified in the Go duration string format (example, 5s ). If both duration and numRequests are specified, then duration is ignored. qps float qps stands for queries-per-second. Number of requests per second sent to the app. Default value is 8.0. connections int Number of parallel connections used to send requests. Default value is 4. payloadURL string (URL) URL from which to download the content that will be used as the request payload. If this field is specified, Iter8 will send HTTP POST requests to the app using this content as the payload. payloadStr string String data to be used as the request payload. If this field is specified, Iter8 will send HTTP POST requests to the app using this string as the payload. contentType string Content type of the payload. This is intended to be used in conjunction with one of the payload* fields. If this field is specified, Iter8 will send HTTP POST requests to the app using this as the Content-Type header value. Metrics \u00b6 This task creates a built-in provider named http . The following metrics are collected by this task: http/request-count : total number of requests sent http/error-count : number of error responses http/error-rate : fraction of error responses http/latency-mean : mean of observed latency values http/latency-stddev : standard deviation of observed latency values http/latency-min : min of observed latency values http/latency-max : max of observed latency values http/latency-pX : X th percentile latency, for X in [50.0, 75.0, 90.0, 95.0, 99.0, 99.9] All latency metrics have msec units.","title":"http"},{"location":"user-guide/tasks/http/#http","text":"Generate requests for an HTTP service and and collect latency and error-related metrics .","title":"http"},{"location":"user-guide/tasks/http/#usage-example","text":"In this experiment, the http task generates requests for https://httpbin.org/get , and collects latency and error-related metrics. The metrics are used by the assess task to validate SLOs. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url=https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean=50 \\ --set assess.SLOs.upper.http/error-count=0","title":"Usage example"},{"location":"user-guide/tasks/http/#parameters","text":"Name Type Description url string (URL) HTTP URL where requests are sent. headers map[string]string HTTP headers to use in the requests. numRequests int Number of requests to be sent to the app. Default value is 100. duration string Duration of this task. Specified in the Go duration string format (example, 5s ). If both duration and numRequests are specified, then duration is ignored. qps float qps stands for queries-per-second. Number of requests per second sent to the app. Default value is 8.0. connections int Number of parallel connections used to send requests. Default value is 4. payloadURL string (URL) URL from which to download the content that will be used as the request payload. If this field is specified, Iter8 will send HTTP POST requests to the app using this content as the payload. payloadStr string String data to be used as the request payload. If this field is specified, Iter8 will send HTTP POST requests to the app using this string as the payload. contentType string Content type of the payload. This is intended to be used in conjunction with one of the payload* fields. If this field is specified, Iter8 will send HTTP POST requests to the app using this as the Content-Type header value.","title":"Parameters"},{"location":"user-guide/tasks/http/#metrics","text":"This task creates a built-in provider named http . The following metrics are collected by this task: http/request-count : total number of requests sent http/error-count : number of error responses http/error-rate : fraction of error responses http/latency-mean : mean of observed latency values http/latency-stddev : standard deviation of observed latency values http/latency-min : min of observed latency values http/latency-max : max of observed latency values http/latency-pX : X th percentile latency, for X in [50.0, 75.0, 90.0, 95.0, 99.0, 99.9] All latency metrics have msec units.","title":"Metrics"},{"location":"user-guide/tasks/ready/","text":"ready \u00b6 Check if a Kubernetes object exists and is ready. Usage example \u00b6 In the following example, the ready task checks if a deployment named httpbin-prod exists and its availability condition is set to true, and a service named httpbin exists. iter8 k launch \\ --set \"tasks={ready,http}\" \\ --set ready.deploy = httpbin-prod \\ --set ready.service = httpbin \\ --set http.url = http://httpbin.default/get \\ --set runner = job Parameters \u00b6 Name Type Description deploy string Name of a Kubernetes deployment. The task checks if the deployment exists and its Available condition is set to true. service string Name of a Kubernetes service. The task checks if the service exists. ksvc string Name of a Knative service. The task checks if the service exists and its Ready condition is set to true. timeout string Timeout for readiness check to succeed. Default value is 60s . namespace string The namespace under which to look for the Kubernetes objects. For experiments that run inside a Kubernetes cluster, the default value of this field is the namespace of the Iter8 experiment ; for experiments that run in the local environment, it is the default namespace. Extensions \u00b6 Iter8 can be easily extended to support readiness checks for any type of Kubernetes object (including objects with custom resource types). Please consider submitting a pull request for such extensions. Readiness checking in Iter8 involves two templates, namely, task.ready and k.role . Extending the readiness checks to new resource types involves modifying these templates. Example \u00b6 Consider the Knative extension for this task; this extension enables Iter8 experiment authors to define readiness check for Knative services . In the following example, the ready task succeed if the Knative service named httpbin exists, and has its Ready condition set to true. iter8 k launch \\ --set \"tasks={ready,http}\" \\ --set ready.ksvc = httpbin \\ --set http.url = http://httpbin.default/get \\ --set runner = job The task.ready and k.role were changed in the following ways to create this extension. task.ready k.role The group/version/resource (GVR) and the condition that should be checked for a Knative Service are defined in this template. 1 2 3 4 5 6 7 8 9 10 11 {{ - if .Values.ready.ksvc }} # task: determine if Knative Service exists and is ready - task : ready with : name : {{ .Values.ready.ksvc | quote }} group : serving.knative.dev version : v1 resource : services condition : Ready {{ - include \"task.ready.tn\" . }} {{ - end }} The role named {{ .Release.Name }}-ready is extended with the Knative apiGroup . 1 2 3 4 5 6 {{ - if .Values.ready.ksvc }} - apiGroups : [ \"serving.knative.dev\" ] resourceNames : [{{ .Values.ready.ksvc | quote }}] resources : [ \"services\" ] verbs : [ \"get\" ] {{ - end }}","title":"ready"},{"location":"user-guide/tasks/ready/#ready","text":"Check if a Kubernetes object exists and is ready.","title":"ready"},{"location":"user-guide/tasks/ready/#usage-example","text":"In the following example, the ready task checks if a deployment named httpbin-prod exists and its availability condition is set to true, and a service named httpbin exists. iter8 k launch \\ --set \"tasks={ready,http}\" \\ --set ready.deploy = httpbin-prod \\ --set ready.service = httpbin \\ --set http.url = http://httpbin.default/get \\ --set runner = job","title":"Usage example"},{"location":"user-guide/tasks/ready/#parameters","text":"Name Type Description deploy string Name of a Kubernetes deployment. The task checks if the deployment exists and its Available condition is set to true. service string Name of a Kubernetes service. The task checks if the service exists. ksvc string Name of a Knative service. The task checks if the service exists and its Ready condition is set to true. timeout string Timeout for readiness check to succeed. Default value is 60s . namespace string The namespace under which to look for the Kubernetes objects. For experiments that run inside a Kubernetes cluster, the default value of this field is the namespace of the Iter8 experiment ; for experiments that run in the local environment, it is the default namespace.","title":"Parameters"},{"location":"user-guide/tasks/ready/#extensions","text":"Iter8 can be easily extended to support readiness checks for any type of Kubernetes object (including objects with custom resource types). Please consider submitting a pull request for such extensions. Readiness checking in Iter8 involves two templates, namely, task.ready and k.role . Extending the readiness checks to new resource types involves modifying these templates.","title":"Extensions"},{"location":"user-guide/tasks/ready/#example","text":"Consider the Knative extension for this task; this extension enables Iter8 experiment authors to define readiness check for Knative services . In the following example, the ready task succeed if the Knative service named httpbin exists, and has its Ready condition set to true. iter8 k launch \\ --set \"tasks={ready,http}\" \\ --set ready.ksvc = httpbin \\ --set http.url = http://httpbin.default/get \\ --set runner = job The task.ready and k.role were changed in the following ways to create this extension. task.ready k.role The group/version/resource (GVR) and the condition that should be checked for a Knative Service are defined in this template. 1 2 3 4 5 6 7 8 9 10 11 {{ - if .Values.ready.ksvc }} # task: determine if Knative Service exists and is ready - task : ready with : name : {{ .Values.ready.ksvc | quote }} group : serving.knative.dev version : v1 resource : services condition : Ready {{ - include \"task.ready.tn\" . }} {{ - end }} The role named {{ .Release.Name }}-ready is extended with the Knative apiGroup . 1 2 3 4 5 6 {{ - if .Values.ready.ksvc }} - apiGroups : [ \"serving.knative.dev\" ] resourceNames : [{{ .Values.ready.ksvc | quote }}] resources : [ \"services\" ] verbs : [ \"get\" ] {{ - end }}","title":"Example"},{"location":"user-guide/topics/group/","text":"Namespaces and groups for Kubernetes experiments \u00b6 Kubernetes experiments are launched within a namespace , and are associated with a unique group within that namespace. For example, consider the following invocation: iter8 k launch -g hbin \\ --set \"tasks={http,assess}\" \\ --set http.url = http://httpbin.default/get \\ --set assess.SLOs.upper.http/latency-mean = 50 In the above invocation, the iter8 k launch command implicitly specifies the namespace as default , and explicitly specifies the group as hbin . If the group name is not specified explicitly, then it is set to default . The namespace can be specified explicitly using the -n or --namespace flags (see here ). The following example illustrates the relationship between namespaces, groups, and experiments. . \u251c\u2500\u2500 namespace1 \u2502 \u251c\u2500\u2500 group-a \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u251c\u2500\u2500 group-b \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u2514\u2500\u2500 group-c \u2502 \u2514\u2500\u2500 experiment \u251c\u2500\u2500 namespace2 \u2502 \u251c\u2500\u2500 group-a \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u251c\u2500\u2500 group-b \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u2514\u2500\u2500 group-c \u2502 \u2514\u2500\u2500 experiment \u2514\u2500\u2500 namespace3 \u2514\u2500\u2500 group-x \u2514\u2500\u2500 experiment Use-cases \u00b6 Run multiple experiments concurrently within a Kubernetes namespace by associating them with distinct groups. These experiments may be associated with the same app or with different apps. Replace a currently running experiment in Kubernetes with a new one. When you invoke iter8 k launch , any previous experiment executions within the group is wiped out and replaced with a fresh experiment that starts to execute. How groups work \u00b6 Under the covers, Iter8 implements each experiment group as a Helm release and each new experiment run within the group as an update of that release.","title":"Namespace and group"},{"location":"user-guide/topics/group/#namespaces-and-groups-for-kubernetes-experiments","text":"Kubernetes experiments are launched within a namespace , and are associated with a unique group within that namespace. For example, consider the following invocation: iter8 k launch -g hbin \\ --set \"tasks={http,assess}\" \\ --set http.url = http://httpbin.default/get \\ --set assess.SLOs.upper.http/latency-mean = 50 In the above invocation, the iter8 k launch command implicitly specifies the namespace as default , and explicitly specifies the group as hbin . If the group name is not specified explicitly, then it is set to default . The namespace can be specified explicitly using the -n or --namespace flags (see here ). The following example illustrates the relationship between namespaces, groups, and experiments. . \u251c\u2500\u2500 namespace1 \u2502 \u251c\u2500\u2500 group-a \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u251c\u2500\u2500 group-b \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u2514\u2500\u2500 group-c \u2502 \u2514\u2500\u2500 experiment \u251c\u2500\u2500 namespace2 \u2502 \u251c\u2500\u2500 group-a \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u251c\u2500\u2500 group-b \u2502 \u2502 \u2514\u2500\u2500 experiment \u2502 \u2514\u2500\u2500 group-c \u2502 \u2514\u2500\u2500 experiment \u2514\u2500\u2500 namespace3 \u2514\u2500\u2500 group-x \u2514\u2500\u2500 experiment","title":"Namespaces and groups for Kubernetes experiments"},{"location":"user-guide/topics/group/#use-cases","text":"Run multiple experiments concurrently within a Kubernetes namespace by associating them with distinct groups. These experiments may be associated with the same app or with different apps. Replace a currently running experiment in Kubernetes with a new one. When you invoke iter8 k launch , any previous experiment executions within the group is wiped out and replaced with a fresh experiment that starts to execute.","title":"Use-cases"},{"location":"user-guide/topics/group/#how-groups-work","text":"Under the covers, Iter8 implements each experiment group as a Helm release and each new experiment run within the group as an update of that release.","title":"How groups work"},{"location":"user-guide/topics/metrics/","text":"Metrics \u00b6 Provider \u00b6 A provider in Iter8 is a data source that supplies metric values. Fully qualified names \u00b6 Metrics are scoped by providers. Providers have unique names, and within the scope of a provider, metrics have unique names. The fully qualified name of a metric refers to the string of the form <provider name>/<metric name> . Following are some examples of fully qualified metric names that appear in Iter8 tutorials. http/latency-mean grpc/error-rate istio-prom/latency-mean Built-in metrics provider \u00b6 Iter8 has built-in metrics providers, namely, http and grpc . Custom metrics provider \u00b6 You can use metrics from any (RESTful) database in Iter8 experiments. Metrics fetched by Iter8 from databases are also referred to as custom metrics. See here to learn more about custom metrics. Metric types \u00b6 Iter8 defines counter and gauge metric types which are analogous to the corresponding metric types defined by Prometheus . We quote from the Prometheus documentation below for their definitions. Counter A counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase or be reset to zero on restart. For example, you can use a counter to represent the number of requests served, tasks completed, or errors. Do not use a counter to expose a value that can decrease. For example, do not use a counter for the number of currently running processes; instead use a gauge. Gauge A gauge is a metric that represents a single numerical value that can arbitrarily go up and down. Gauges are typically used for measured values like temperatures or current memory usage, but also \"counts\" that can go up and down, like the number of concurrent requests.","title":"Metrics"},{"location":"user-guide/topics/metrics/#metrics","text":"","title":"Metrics"},{"location":"user-guide/topics/metrics/#provider","text":"A provider in Iter8 is a data source that supplies metric values.","title":"Provider"},{"location":"user-guide/topics/metrics/#fully-qualified-names","text":"Metrics are scoped by providers. Providers have unique names, and within the scope of a provider, metrics have unique names. The fully qualified name of a metric refers to the string of the form <provider name>/<metric name> . Following are some examples of fully qualified metric names that appear in Iter8 tutorials. http/latency-mean grpc/error-rate istio-prom/latency-mean","title":"Fully qualified names"},{"location":"user-guide/topics/metrics/#built-in-metrics-provider","text":"Iter8 has built-in metrics providers, namely, http and grpc .","title":"Built-in metrics provider"},{"location":"user-guide/topics/metrics/#custom-metrics-provider","text":"You can use metrics from any (RESTful) database in Iter8 experiments. Metrics fetched by Iter8 from databases are also referred to as custom metrics. See here to learn more about custom metrics.","title":"Custom metrics provider"},{"location":"user-guide/topics/metrics/#metric-types","text":"Iter8 defines counter and gauge metric types which are analogous to the corresponding metric types defined by Prometheus . We quote from the Prometheus documentation below for their definitions. Counter A counter is a cumulative metric that represents a single monotonically increasing counter whose value can only increase or be reset to zero on restart. For example, you can use a counter to represent the number of requests served, tasks completed, or errors. Do not use a counter to expose a value that can decrease. For example, do not use a counter for the number of currently running processes; instead use a gauge. Gauge A gauge is a metric that represents a single numerical value that can arbitrarily go up and down. Gauges are typically used for measured values like temperatures or current memory usage, but also \"counts\" that can go up and down, like the number of concurrent requests.","title":"Metric types"},{"location":"user-guide/topics/parameters/","text":"Experiment Parameters \u00b6 Iter8 is built on Helm . Iter8 experiments can be configured with parameters using the same mechanisms provided by Helm for setting chart values . The set of configurable parameters of an experiment includes the parameters of the tasks involved in the experiment. Iter8 uses the convention that the parameters of a task are nested under the name of that task. In the following example, the url parameter of the http task is nested under the http object, and the SLOs parameter of the assess task is nested under the assess object. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url = https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 All the parameters of a task or an experiment are optional unless indicated otherwise in the documentation of the task or expereiment.","title":"Experiment parameters"},{"location":"user-guide/topics/parameters/#experiment-parameters","text":"Iter8 is built on Helm . Iter8 experiments can be configured with parameters using the same mechanisms provided by Helm for setting chart values . The set of configurable parameters of an experiment includes the parameters of the tasks involved in the experiment. Iter8 uses the convention that the parameters of a task are nested under the name of that task. In the following example, the url parameter of the http task is nested under the http object, and the SLOs parameter of the assess task is nested under the assess object. iter8 launch \\ --set \"tasks={http,assess}\" \\ --set http.url = https://httpbin.org/get \\ --set assess.SLOs.upper.http/latency-mean = 50 \\ --set assess.SLOs.upper.http/error-count = 0 All the parameters of a task or an experiment are optional unless indicated otherwise in the documentation of the task or expereiment.","title":"Experiment Parameters"}]}